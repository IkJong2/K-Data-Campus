{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"20190802_박종익_CNN_실습.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"lJKtgmNc774E","colab_type":"text"},"source":["링크 주소: tinyurl.com/skt-04-12\n","다운로드 후 google drive 업로드\n","Colaboratory로 열기."]},{"cell_type":"markdown","metadata":{"id":"9SH_g6i-jMBh","colab_type":"text"},"source":["### pyTorch 를 비롯해 오늘 실습에 필요한 파이썬 라이브러리를 읽어들입니다."]},{"cell_type":"code","metadata":{"id":"s-5K8m1hfCRC","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn #\n","import torch.nn.functional as F #\n","import torchvision # 이미지 관련 처리, Pretrained Model 관련된 Package 입니다. \n","import torchvision.datasets as vision_dsets\n","import torchvision.transforms as transforms # 이미지 처리 (Vison) 관련된 transformation이 정의 되어 있습니다. ... data load 할 때 쓰는 것\n","import torch.optim as optim # pytorch 에서 정의한 수 많은 optimization function 들이 들어 있습니다. ... Gradient optimizer 할때\n","from torch.utils import data\n","\n","import numpy as np\n","import matplotlib.pyplot as plt # 시각화를 위한 패키지입니다."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Yz8VMAXSjYCe","colab_type":"text"},"source":["### Hyper-parameter 세팅 및 기타 변수 지정"]},{"cell_type":"code","metadata":{"id":"q-G0yNhJjLtZ","colab_type":"code","colab":{}},"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu' # pytorch0.4.0 이상 버젼에서 gpu 설정하는 방식, tensor.to(device) 이런식으로 사용\n","lr = 0.001\n","batch_size = 128\n","best_acc = 0  # best test accuracy\n","start_epoch = 0  # start from epoch 0 or last checkpoint epoch"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cXhH8tYwtQN7","colab_type":"text"},"source":["### 다양한 함수 연습"]},{"cell_type":"code","metadata":{"id":"gfkq3vn1ta4r","colab_type":"code","outputId":"23ab1424-5fad-4e2e-daa5-1e9f98b3a671","executionInfo":{"status":"ok","timestamp":1564710097183,"user_tz":-540,"elapsed":989,"user":{"displayName":"IkJong P","photoUrl":"https://lh5.googleusercontent.com/-XMHI3In5VGY/AAAAAAAAAAI/AAAAAAAATWk/u_tsKGQQW3I/s64/photo.jpg","userId":"13049101358773066030"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["# torch.view 연습\n","\n","sample = torch.randn(2000,3,64,64) #.to(device) 하면 gpu로 넘어가는 것!\n","##이건 normal에서 뽑겠다! 2000 : batch 3: channel 64: height 64 : width\n","\n","#기본적으로, 이미지 처리를 할때 파이토치의 텐서 구성은 Batch, Channel, Height, Width로 구성.\n","#코딩 시 B,C,H,W로 변수화하여 사용하면 편리\n","\n","B,C,H,W = sample.size()\n","\n","# sample => (2000, 64, 64, 3).  \n","sample_1 = sample.view(B, -1) #위 sample 을 (2000, 3*64*64)으로 바꿔보세요. \n","##batch dimension과 element들~\n","\n","print(sample_1.size())\n","sample.size()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["torch.Size([2000, 12288])\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["torch.Size([2000, 3, 64, 64])"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"nIEfCDZebJ5f","colab_type":"code","outputId":"e458aff8-849c-4250-981a-0fe9a7537521","executionInfo":{"status":"ok","timestamp":1564710097184,"user_tz":-540,"elapsed":565,"user":{"displayName":"IkJong P","photoUrl":"https://lh5.googleusercontent.com/-XMHI3In5VGY/AAAAAAAAAAI/AAAAAAAATWk/u_tsKGQQW3I/s64/photo.jpg","userId":"13049101358773066030"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#위 sample 을 (2000*3, 64*64)로 바꿔보세요.\n","sample_2 = sample.view(B*C, H*W) ##view란 reshape와 같은 것!!\n","print(sample_2.size())"],"execution_count":5,"outputs":[{"output_type":"stream","text":["torch.Size([6000, 4096])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0iH_HikgtcN_","colab_type":"code","outputId":"d82a5e11-18c2-40d7-d00b-4e794b8c4397","executionInfo":{"status":"ok","timestamp":1564709272101,"user_tz":-540,"elapsed":1465,"user":{"displayName":"IkJong P","photoUrl":"https://lh5.googleusercontent.com/-XMHI3In5VGY/AAAAAAAAAAI/AAAAAAAATWk/u_tsKGQQW3I/s64/photo.jpg","userId":"13049101358773066030"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["# torch.view 다른 예제\n","a = torch.FloatTensor(5,20,100) ## just batch channel height\n","a1 = a.view(2, 10, -1) ##-1은 나머지를 몰아주기!\n","print(a1.size())\n","a2 = a.view(-1,10, 200)\n","print(a2.size())"],"execution_count":5,"outputs":[{"output_type":"stream","text":["torch.Size([2, 10, 500])\n","torch.Size([5, 10, 200])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FpJXUhHfZqqk","colab_type":"code","outputId":"b5ab8a36-1267-43cc-de68-36e4b3219d35","executionInfo":{"status":"ok","timestamp":1564709274462,"user_tz":-540,"elapsed":1006,"user":{"displayName":"IkJong P","photoUrl":"https://lh5.googleusercontent.com/-XMHI3In5VGY/AAAAAAAAAAI/AAAAAAAATWk/u_tsKGQQW3I/s64/photo.jpg","userId":"13049101358773066030"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["# dimension간의 이동을 하고 싶으면? ex) B,C,H,W => B,C,W,H \n","sample = torch.randn(2000,3,32,64)\n","sample_1 = sample.permute(0,1,3,2) ##permute의 경우 2랑 3이랑 자리를 바꾸겠다!\n","print(sample.size())\n","print(sample_1.size())"],"execution_count":6,"outputs":[{"output_type":"stream","text":["torch.Size([2000, 3, 32, 64])\n","torch.Size([2000, 3, 64, 32])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AtmhGsJBbVSu","colab_type":"code","outputId":"a3f9ad57-464a-4722-f358-62bed13c6d72","executionInfo":{"status":"ok","timestamp":1564709274463,"user_tz":-540,"elapsed":611,"user":{"displayName":"IkJong P","photoUrl":"https://lh5.googleusercontent.com/-XMHI3In5VGY/AAAAAAAAAAI/AAAAAAAATWk/u_tsKGQQW3I/s64/photo.jpg","userId":"13049101358773066030"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# sample_1 변수의 디멘션을 다시 원래대로 돌리려면?\n","sample_2 = sample_1.permute(0,1,3,2)\n","print(torch.equal(sample,sample_2))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["True\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WbflffF5jkhF","colab_type":"text"},"source":["### Convolution layer  가지고 놀기 "]},{"cell_type":"code","metadata":{"id":"ekBQ5Gv5tdWt","colab_type":"code","outputId":"6cd985d5-a38e-4d46-b221-e2953c4c4fd5","executionInfo":{"status":"ok","timestamp":1564547221359,"user_tz":-540,"elapsed":1011,"user":{"displayName":"IkJong P","photoUrl":"https://lh5.googleusercontent.com/-XMHI3In5VGY/AAAAAAAAAAI/AAAAAAAATWk/u_tsKGQQW3I/s64/photo.jpg","userId":"13049101358773066030"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# torch.nn.conv 연습\n","# 클래스 구성: nn.Conv2d(in, out, filter_size, stride, padding)\n","# 아웃풋사이즈가 이와같이 되도록 되도록 해봅니다: (16, 128, 32, 32)\n","input1 = torch.zeros(16, 3, 64, 64) ## B C H W\n","conv1 = nn.Conv2d(3, 512, 3, 1, 1) ##input_ch output_ch, filter, stride , padding\n","## 16 ,3, 64, 64 => 16, 512, 64, 64 ... if filter -> 5? -> padding 2 이런식으로 하면 spatial이 유지가 된다!\n","conv2 = nn.Conv2d(512,128,4,2,1)\n","## 16, 512, 64, 64 => 16, 128, 32, 32 ...stride를 늘리게 되면 spatial이 반토막이 나버린다.\n","\n","out = conv1(input1)\n","output = conv2(out)\n","\n","print(output.size())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([16, 128, 32, 32])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-4y9j5V1toLX","colab_type":"code","outputId":"3fd1aa33-128e-4a61-9025-cd94a9a93f3c","executionInfo":{"status":"ok","timestamp":1564547313238,"user_tz":-540,"elapsed":585,"user":{"displayName":"IkJong P","photoUrl":"https://lh5.googleusercontent.com/-XMHI3In5VGY/AAAAAAAAAAI/AAAAAAAATWk/u_tsKGQQW3I/s64/photo.jpg","userId":"13049101358773066030"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# torch.nn.conv 연습\n","# 클래스 구성: nn.Conv2d(in, out, filter_size, stride, padding)\n","# 아웃풋사이즈가 이와같이 되도록 해봅니다: (16, 512, 16, 16)\n","input = torch.zeros(16, 3, 64, 64) \n","conv1 = nn.Conv2d(3,64,3,1,1) ## 16, 3, 64, 64 => 16, 64, 64, 64\n","conv2 = nn.Conv2d(64,512,3,4,1) ##16, 64, 64, 64 => 16, 512, (64/4), (64/4)\n","\n","##stride가 4인거는 네트워크에서 사용하지 않는다!! 그러나 이동하게 되면 2^2만큼 줄어들게 된다.\n","\n","out = conv1(input)\n","output = conv2(out)\n","\n","print(output.size())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([16, 512, 16, 16])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"z98BxwUEtzMV","colab_type":"code","outputId":"151805db-9a7b-4940-8ab1-52d9a4c85903","executionInfo":{"status":"ok","timestamp":1564547493602,"user_tz":-540,"elapsed":1293,"user":{"displayName":"IkJong P","photoUrl":"https://lh5.googleusercontent.com/-XMHI3In5VGY/AAAAAAAAAAI/AAAAAAAATWk/u_tsKGQQW3I/s64/photo.jpg","userId":"13049101358773066030"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#quiz 4 (torch.nn.conv 연습)\n","# 클래스 구성: nn.Conv2d(in, out, filter_size, stride, padding)\n","# 아웃풋사이즈가 이와같이 되도록 해봅니다: (16, 512, 64, 64)\n","input = torch.zeros(16, 3, 64, 64)\n","conv1 = nn.Conv2d(3,64,3,1,1) \n","conv2 = nn.Conv2d(64,512,3,1,1)\n","\n","out = conv1(input)\n","output = conv2(out)\n","\n","print(output.size()) ##이 아이는 stride를 건드리지 않아서 그냥 그대로 간다~"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([16, 512, 64, 64])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"M0qEKErJjfFm","colab_type":"text"},"source":["### 데이터 로딩"]},{"cell_type":"markdown","metadata":{"id":"nWG00oKqntRB","colab_type":"text"},"source":["Data Augmentation?"]},{"cell_type":"code","metadata":{"id":"gbSxD67XjdzL","colab_type":"code","outputId":"8e5f58f2-5e88-4f19-fa9f-cfcd232e147f","executionInfo":{"status":"ok","timestamp":1564710113222,"user_tz":-540,"elapsed":3391,"user":{"displayName":"IkJong P","photoUrl":"https://lh5.googleusercontent.com/-XMHI3In5VGY/AAAAAAAAAAI/AAAAAAAATWk/u_tsKGQQW3I/s64/photo.jpg","userId":"13049101358773066030"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["# Data\n","print('==> Preparing data..')\n","# 데이터 전처리를 위한 코드\n","transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4), # 4만큼의 padding을 부여한 후, 32x32로 random cropping\n","    ##이미지가 있으면, 랜덤하게 자르는 것!\n","    transforms.RandomHorizontalFlip(), # 0.5의 확률로 이미지 좌우 반전하여 넣어줌\n","    ## 위에 있던 것을 좌우를 바꿔버린다.\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), # cifar10(0~1)의 r,g,b 채널 별 평균 및 분산으로 normalization => N(0,1)의 정규분포를 따르도록 만들어준 후 input으로 넣어줍니다.\n","    ## 우리가 사용하는 학습데이터의 mu와 시그마를 구해준다. rgb에 대한 것들!! mean sd\n","])\n","\n","# 랜덤 cropping을 하고, 이미지 좌우반전을 해주는 이유 : ???\n","\n","# 데이터 전처리를 위한 코드\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), # cifar10(0~1)의 r,g,b 채널 별 평균 및 분산으로 normalization => N(0,1)의 정규분포를 따르도록 만들어준 후 input으로 넣어줍니다.\n","    ## 우리가 사용하는 테스트데이터의 mu와 시그마를 구해준다. rgb에 대한 것들!! mean sd\n","])\n","\n","# 데이터 로딩\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=1)\n","## batch_size가 들어갔다! 우리가 가지고 있는 데이터/batch_size 해주면 mini batch의 수가 나오게 된다!!\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=1)\n","\n","classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["==> Preparing data..\n","Files already downloaded and verified\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mXEmr4oVnyRv","colab_type":"code","outputId":"ef43ec32-2911-469c-b2ad-f0401847487a","executionInfo":{"status":"ok","timestamp":1564710120341,"user_tz":-540,"elapsed":5610,"user":{"displayName":"IkJong P","photoUrl":"https://lh5.googleusercontent.com/-XMHI3In5VGY/AAAAAAAAAAI/AAAAAAAATWk/u_tsKGQQW3I/s64/photo.jpg","userId":"13049101358773066030"}},"colab":{"base_uri":"https://localhost:8080/","height":437}},"source":["def showImages(image, row):\n","  \n","  for _ in range(row):  \n","  \n","    idx = np.random.choice(batch_size, 6)     # 0 ~ 127 의 정수 중 6 개를 임의로 선택\n","    images =image.numpy()[idx].transpose(0,2,3,1).clip(0,1)         # 선택된 index 에 해당하는 이미지를 가져옴\n","    plt.figure(figsize = (15, 90))     # 세로 길이 15, 가로 길이 15 * 6 의 화면 생성\n","    \n","    for i in range(161, 167):    \n","    \n","      plt.subplot(i)\n","      plt.imshow(images[i - 161])\n","      plt.xticks([])\n","      plt.yticks([])    \n","    \n","    plt.show()  \n","\n","for i, (image, labels) in enumerate(trainloader): \n","  \n","  showImages(image.squeeze(), 3)\n","  break"],"execution_count":7,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAA1oAAACMCAYAAABlLdgxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n","text/plain":["<Figure size 1080x6480 with 6 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAA1oAAACMCAYAAABlLdgxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 1080x6480 with 6 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAA1oAAACMCAYAAABlLdgxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAISMCy0AAAAACNn/ByT4f448jiT+AAAAAElFTkSuQmCC\n","text/plain":["<Figure size 1080x6480 with 6 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"QGj5qoFcn0FF","colab_type":"code","outputId":"6ef58968-0a74-4328-d161-597923160125","executionInfo":{"status":"ok","timestamp":1564547673674,"user_tz":-540,"elapsed":573,"user":{"displayName":"IkJong P","photoUrl":"https://lh5.googleusercontent.com/-XMHI3In5VGY/AAAAAAAAAAI/AAAAAAAATWk/u_tsKGQQW3I/s64/photo.jpg","userId":"13049101358773066030"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["print('[info] # of train batch : ' ,len(trainloader))\n","print('[info] # of test batch : ', len(testloader))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[info] # of train batch :  391\n","[info] # of test batch :  100\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0QOyd5gRUFn8","colab_type":"text"},"source":["제일 필요한 것은 train코드와 model 코드가 가장 중요하다!!\n","\n","이정도는 직접 작성해보자!!\n","\n","그리고 우리가 밑에서 하는 것들은 Cifar이다!"]},{"cell_type":"code","metadata":{"id":"vJ9lTPT9n1dM","colab_type":"code","colab":{}},"source":["def train_network(net,optimizer,trainloader, epochs=5):\n","  for epoch in range(epochs):  # loop over the dataset multiple times\n","    ## epoch은 그냥 for문을 돌린다~\n","\n","      running_loss = 0.0 # running loss를 저장하기 위한 변수입니다. \n","      for i, data in enumerate(trainloader): # 한 Epoch 만큼 돕니다. 매 iteration 마다 정해진 Batch size 만큼 데이터를 뱉습니다. \n","        ## 여기서는 한 mini batch씩 가지고 온다.\n","          # get the inputs\n","          inputs, labels = data # DataLoader iterator의 반환 값은 input_data 와 labels의 튜플 형식입니다. \n","          inputs = inputs.to(device) # Pytorch에서 nn.Module 에 넣어 Backprop을 계산 하기 위해서는 gpu 연동을 이와 같이 해줘야 합니다.\n","          ## 이걸 하게 되면 gpu에 올리는 것! 아까는 cuda와 같음\n","          labels = labels.to(device)\n","          # zero the parameter gradients\n","          optimizer.zero_grad()    #  현재 기존의 backprop을 계산하기 위해서 저장했던 activation buffer 를 비웁니다.\n","          ## 매번 gradient를 담을 수 없으니까 비워준다.\n","          \n","          # forward + backward + optimize\n","          outputs = net(inputs) # input 을 넣은 위 network 로 부터 output 을 얻어냅니다. \n","          ## net에서 input을 받아서 output을 구함\n","          loss = criterion(outputs, labels) # loss fucntion에 주어진 target과 output 의 score를 계산하여 반환합니다. \n","          ## 로스를 구한 후 back을 돌려준다.\n","          loss.backward() # * Scalar Loss value를 Backward() 해주게 되면 주어진 loss값을 바탕으로 backpropagation이 진행됩니다. \n","          optimizer.step() # 계산된 Backprop 을 바탕으로 optimizer가 gradient descenting 을 수행합니다. \n","          ## 마지막에 optimizer!\n","\n","          # print statistics\n","          running_loss += loss.item()\n","          if (i+1) % 100 == 0:    # print every 500 mini-batches\n","              print('[%d, %5d] loss: %.3f' %\n","                    (epoch + 1, i + 1, running_loss / 100))\n","              running_loss = 0.0\n","\n","  print('Finished Training')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3F3ZmR6-oIH3","colab_type":"code","colab":{}},"source":["def test(model,test_loader):\n","  model.eval() # Eval Mode 왜 해야 할까요?  --> nn.Dropout BatchNorm 등의 Regularization 들이 test 모드로 들어가게 되기 때문입니다. \n","  ##test의 경우 dropdout 이나 batch_norm의 경우 빼는 것을 방지하고자\n","  ## 결국 train batch를 합쳐서 mu랑 sigma를 구해주기 위해서\n","  test_loss = 0\n","  correct = 0\n","  for data, target in test_loader:\n","    data = data.to(device)\n","    target = target.to(device)  # 기존의 train function의 data 처리부분과 같습니다. \n","    output = model(data) \n","    ##여기선 optimize가 들어갈 필요가 없다!! just 스코어만 내면 되기에...\n","    \n","    pred = output.max(1, keepdim=True)[1] # get the index of the max \n","    ## 10개의 스코어들 중에 가장 높은 것을 가지고 오겠다.\n","    correct += pred.eq(target.view_as(pred)).sum().item() # 정답 데이터의 갯수를 반환합니다. \n","    ## 결국 똑같다면 카운팅을 하겠다.\n","\n","  test_loss /= len(test_loader.dataset)\n","  print('\\nTest set:  Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","      correct, len(test_loader.dataset),\n","      100. * correct / len(test_loader.dataset)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wRrx1X1RN-_Z","colab_type":"code","colab":{}},"source":["def count_parameters(model): # 모델 파라미터 개수를 리턴하는 함수를 하나 만들어둡니다\n","  return sum(p.numel() for p in model.parameters() if p.requires_grad)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rSEcl4__bWaX","colab_type":"text"},"source":["train_network(mnist_net,optimizer,trainloader) 호출할 때,\n","\n","init을 통해서 모델을 들어간 후 처음 layers 생성을 다 해준다\n","\n","그리고 train_network 돌다가 net에 도달하게 되면 input으로 forward에 있는 x로 받게 되어서\n","\n"," foward propagation을 진행하게 된다.\n"," "]},{"cell_type":"markdown","metadata":{"id":"I5gzkWcJoUxC","colab_type":"text"},"source":["### MNIST에서 사용했던 MLP를 적용해보자!"]},{"cell_type":"code","metadata":{"id":"9fwsRmXDoL8d","colab_type":"code","colab":{}},"source":["class MNIST_Net(nn.Module):\n","    def __init__(self):\n","        super(MNIST_Net, self).__init__()\n","        \n","        layer_list = [] # 이 리스트에 모든 Layer 를 순차적으로 append 해보겠습니다. ... 배열!! why?? Sequential 하기 위해\n","        layer_list.append(nn.Linear(3*32*32,256)) #Layer 1 인풋 사이즈가 32*32로 변경되었기 때문에 바꿔줍니다!!\n","        ##view를 통해서 몰아줌\n","        layer_list.append(nn.BatchNorm1d(256))#BatchNorm1\n","        layer_list.append(nn.ReLU()) # Relu \n","        layer_list.append(nn.Linear(256, 64)) # Layer 2\n","        layer_list.append(nn.BatchNorm1d(64)) #BatchNorm1\n","        layer_list.append(nn.ReLU())# Relu \n","        layer_list.append(nn.Linear(64, 10)) # Layer 3\n","        self.net  = nn.Sequential(*layer_list) # nn.Sequential 에 layer list를 넘겨 줍니다.\n","        ##최종 아웃풋 레이어\n","       \n","    def forward(self, x):\n","        x = x.view(-1,32*32*3) # 기존의 (128, 3, 32, 32)를 일자로 쭉 늘립니다.\n","        x = self.net(x) # 넣은 순서대로 적용이 됩니다. \n","        return x\n","      ##위에서 했던 input이 forward함수로 넘어와서 x로 들어가게 된다. ???"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OXDe9e8goV4k","colab_type":"code","colab":{}},"source":["mnist_net = MNIST_Net().to(device) # 생성한 뉴럴넷 Instance를 생성하고 빠른 학습을 위해 cuda 에 올립니다. \n","criterion = nn.CrossEntropyLoss() # Loss Function을 정의 합니다. 여기서는 cross entrophy loss 를 사용합니다. \n","optimizer = optim.Adam(mnist_net.parameters(), lr=lr) # optimizer는 이와 같이 training 할 Parameter와 learning rate를 인자로 줍니다. "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ET-9RK75oX3w","colab_type":"code","outputId":"ad8dd2f1-97e0-4746-a7e5-6687a6d15055","executionInfo":{"status":"ok","timestamp":1564548355644,"user_tz":-540,"elapsed":62433,"user":{"displayName":"IkJong P","photoUrl":"https://lh5.googleusercontent.com/-XMHI3In5VGY/AAAAAAAAAAI/AAAAAAAATWk/u_tsKGQQW3I/s64/photo.jpg","userId":"13049101358773066030"}},"colab":{"base_uri":"https://localhost:8080/","height":298}},"source":["train_network(mnist_net,optimizer,trainloader)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[1,   100] loss: 2.005\n","[1,   200] loss: 1.814\n","[1,   300] loss: 1.741\n","[2,   100] loss: 1.648\n","[2,   200] loss: 1.625\n","[2,   300] loss: 1.614\n","[3,   100] loss: 1.576\n","[3,   200] loss: 1.548\n","[3,   300] loss: 1.534\n","[4,   100] loss: 1.518\n","[4,   200] loss: 1.506\n","[4,   300] loss: 1.500\n","[5,   100] loss: 1.475\n","[5,   200] loss: 1.482\n","[5,   300] loss: 1.479\n","Finished Training\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wO5Aa_PCoYxL","colab_type":"code","outputId":"580ea940-631d-409d-b4ef-a9c2c5286d98","executionInfo":{"status":"ok","timestamp":1562084932438,"user_tz":-540,"elapsed":2964,"user":{"displayName":"Wonwoong Cho","photoUrl":"","userId":"14212918309461362604"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["test(mnist_net,testloader)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","Test set:  Accuracy: 4995/10000 (50%)\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"58fk39tBo91s","colab_type":"text"},"source":["### 심플한 CNN 모델을 만들어 봅시다.\n","\n","<구성>\n","\n","Layer 1 - input: 3 x 32 x 32, output: 64 x 32 x 32- ReLU + BatchNorm\n","\n","Layer 2 - input: 64 x 32 x 32, output: 128 x 16 x 16- ReLU + BatchNorm (Down Conv라고 부릅니다.)\n","\n","Layer 5 - Global Average Pooling (128 x 16 x 16 => 128 x 1 x 1)\n","\n","Layer 6 - input: 128 x 1 x 1, output 10 x 1 x 1 - ReLU + BatchNorm\n","\n","![대체 텍스트](https://cdn-images-1.medium.com/max/1600/1*D47ER7IArwPv69k3O_1nqQ.png)"]},{"cell_type":"code","metadata":{"id":"Uf3CEXKVpi_0","colab_type":"code","colab":{}},"source":["class DiyCNN(nn.Module):\n","  def __init__(self):\n","    super(DiyCNN, self).__init__()\n","    layers = []\n","    ## 여기서 왜 쭉 넓혀 주는지?? 처음에 넓게 줌으로써 feature를 뽑는다. ##input channel을 설정해주어야 한다!\n","    layers += [nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=1, padding=3)] # 첫 conv는 보통 receptive field를 최대한 넓혀준 후 feature를 뽑아줍니다.\n","    layers += [nn.BatchNorm2d(64)] # 앞선 MLP 시간과 달리 spatial resolution이 살아있기 때문에, batchnorm 2d를 사용해 줍니다. ... output channel에 맞춰줘야 한다~\n","    layers += [nn.ReLU()]\n","    \n","    layers += [nn.Conv2d(64,128,3,2,1)] # Bx64x32x32 => Bx128x16x16 ... 321 은 반토막\n","    layers += [nn.BatchNorm2d(128)] \n","    layers += [nn.ReLU()]\n","    \n","    layers += [nn.Conv2d(128,256,3,2,1)] # Bx128x16x16 => Bx256x8x8\n","    layers += [nn.BatchNorm2d(256)]\n","    layers += [nn.ReLU()]\n","    \n","    layers += [nn.Conv2d(256,512,3,2,1)] # Bx256x8x8 => Bx512x4x4\n","    layers += [nn.BatchNorm2d(512)]\n","    layers += [nn.ReLU()]\n","    \n","    layers += [nn.AdaptiveAvgPool2d(1)] # 512 x 1 \n","    ## 그냥 avg pooling을 한다~~ 각각의 블락이 channel인데\n","    ## 뭐를 없앤다....??? \n","    ## 1을 넣은 이유는 내부적으로 같이 처리를 하겠다는 것\n","    \n","    layers += [nn.Conv2d(512, 10, 1, 1, 0)] # 128 x 10 x 1 x 1 \n","    ## 최종 아웃풋을 내기 위해.... 그렇다면 fully connected는 어디에...??\n","    \n","    self.main = nn.Sequential(*layers)\n","    \n","  def forward(self, x):\n","    return self.main(x).squeeze(3).squeeze(2)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vorrzAVgq4Dg","colab_type":"text"},"source":["##### 정답: 자신을 위해 가능한 확인하지 않고 진행해주세요~"]},{"cell_type":"code","metadata":{"id":"6J1292kjL1tM","colab_type":"code","colab":{}},"source":["class DiyCNN(nn.Module):\n","  def __init__(self):\n","    super(DiyCNN, self).__init__()\n","    layers = []\n","\n","    layers += [nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=2, padding=1)] # 첫 conv는 보통 receptive field를 최대한 넓혀준 후 feature를 뽑아줍니다.\n","    layers += [nn.BatchNorm2d(64)] # 앞선 MLP 시간과 달리 spatial resolution이 살아있기 때문에, batchnorm 2d를 사용해 줍니다.\n","    layers += [nn.ReLU()] ##batch-norm을 하게 되면 값들을 중앙으로 좀 모아주는 역할 ... 값이 너무 커지지 않게! like scaling\n","    \n","    layers += [nn.Conv2d(64, 128, 3, 2, 1)]\n","    layers += [nn.BatchNorm2d(128)]\n","    layers += [nn.ReLU()]\n","    \n","    layers += [nn.Conv2d(128, 256, 3, 2, 1)]\n","    layers += [nn.BatchNorm2d(256)]\n","    layers += [nn.ReLU()]\n","    \n","    layers += [nn.Conv2d(256, 512, 3, 2, 1)]\n","    layers += [nn.BatchNorm2d(512)]\n","    layers += [nn.ReLU()]\n","    \n","    layers += [nn.AdaptiveAvgPool2d(1)]\n","    \n","    layers += [nn.Conv2d(512, 10, 1, 1, 0)] \n","    \n","    self.main = nn.Sequential(*layers)\n","    \n","  def forward(self, x):\n","    return self.main(x).squeeze(3).squeeze(2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WZjiCK5vre9t","colab_type":"code","outputId":"7e49d346-ff4a-46f6-d36a-ce8f2c14fe86","executionInfo":{"status":"ok","timestamp":1564709555075,"user_tz":-540,"elapsed":1368,"user":{"displayName":"IkJong P","photoUrl":"https://lh5.googleusercontent.com/-XMHI3In5VGY/AAAAAAAAAAI/AAAAAAAATWk/u_tsKGQQW3I/s64/photo.jpg","userId":"13049101358773066030"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cifar_net = DiyCNN().to(device) # 생성한 뉴럴넷 Instance를 생성하고 빠른 학습을 위해 cuda 에 올립니다. \n","criterion = nn.CrossEntropyLoss() # Loss Function을 정의 합니다. 여기서는 cross entrophy loss 를 사용합니다. \n","optimizer = optim.Adam(cifar_net.parameters(), lr=lr) # optimizer는 이와 같이 training 할 Parameter와 learning rate를 인자로 줍니다. \n","\n","print('[info] number of model parameter - %d'%(count_parameters(cifar_net))) # 방금 구성한 모형의 파라미터 개수를 프린트 해봅니다."],"execution_count":23,"outputs":[{"output_type":"stream","text":["[info] number of model parameter - 1558026\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pE8APJgRrgfS","colab_type":"code","outputId":"86f77556-c5a8-42a0-876b-191a2ed1a511","executionInfo":{"status":"ok","timestamp":1564709703137,"user_tz":-540,"elapsed":147358,"user":{"displayName":"IkJong P","photoUrl":"https://lh5.googleusercontent.com/-XMHI3In5VGY/AAAAAAAAAAI/AAAAAAAATWk/u_tsKGQQW3I/s64/photo.jpg","userId":"13049101358773066030"}},"colab":{"base_uri":"https://localhost:8080/","height":298}},"source":["train_network(cifar_net,optimizer,trainloader)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["[1,   100] loss: 1.735\n","[1,   200] loss: 1.481\n","[1,   300] loss: 1.373\n","[2,   100] loss: 1.193\n","[2,   200] loss: 1.150\n","[2,   300] loss: 1.103\n","[3,   100] loss: 1.012\n","[3,   200] loss: 1.004\n","[3,   300] loss: 0.978\n","[4,   100] loss: 0.902\n","[4,   200] loss: 0.906\n","[4,   300] loss: 0.885\n","[5,   100] loss: 0.838\n","[5,   200] loss: 0.827\n","[5,   300] loss: 0.824\n","Finished Training\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OcX_blYBrhef","colab_type":"code","outputId":"a1e2a5ce-ff60-4448-e062-fa2a03dea2b1","executionInfo":{"status":"ok","timestamp":1564548827562,"user_tz":-540,"elapsed":2515,"user":{"displayName":"IkJong P","photoUrl":"https://lh5.googleusercontent.com/-XMHI3In5VGY/AAAAAAAAAAI/AAAAAAAATWk/u_tsKGQQW3I/s64/photo.jpg","userId":"13049101358773066030"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["test(cifar_net,testloader)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","Test set:  Accuracy: 7479/10000 (75%)\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wMBJ5Vla_Wkd","colab_type":"text"},"source":["### Average Pooling 대신 Linear Layer로!"]},{"cell_type":"code","metadata":{"id":"-YXvUnMAys_0","colab_type":"code","colab":{}},"source":["## 그냥 우리의 학습을 위한 네트워크~\n","\n","class DiyCNN(nn.Module):\n","  def __init__(self):\n","    super(DiyCNN, self).__init__()\n","    layers = []\n","\n","    layers += [nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=2, padding=1)] # 첫 conv는 보통 receptive field를 최대한 넓혀준 후 feature를 뽑아줍니다.\n","    layers += [nn.BatchNorm2d(64)] # 앞선 MLP 시간과 달리 spatial resolution이 살아있기 때문에, batchnorm 2d를 사용해 줍니다.\n","    layers += [nn.ReLU()]\n","    \n","    layers += [nn.Conv2d(64, 128, 4, 2, 1)]\n","    layers += [nn.BatchNorm2d(128)]\n","    layers += [nn.ReLU()]\n","    \n","    layers += [nn.Conv2d(128, 256, 4, 2, 1)]\n","    layers += [nn.BatchNorm2d(256)]\n","    layers += [nn.ReLU()]\n","    \n","    layers += [nn.Conv2d(256, 512, 4, 2, 1)]\n","    layers += [nn.BatchNorm2d(512)]\n","    layers += [nn.ReLU()] # 128 x 512*4 -> 128 x 512\n","    \n","    classifier = []\n","    \n","    ## 여기부터 바뀐 코드!!!\n","   \n","    \n","    classifier += [nn.Linear(512*4,512)] ##이게 그냥 파라메타 개수 아까 avgpool보다 훨씬 많다!!!\n","    ## 그럼에도 불구하고 feature를 잘 보여준다\n","    \n","    classifier += [nn.Linear(512,10)]\n","    \n","    ## 마지막에 VGG 네트워크에서 뭐라뭐라...\n","    \n","    self.main = nn.Sequential(*layers)\n","    self.classifier = nn.Sequential(*classifier)\n","    \n","  def forward(self, x):\n","    out = self.main(x) # 128 x 512 x 2 x2\n","    out = out.view(out.size(0),-1)\n","    out = self.classifier(out)\n","    return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JbVONDRyz1RK","colab_type":"code","outputId":"e32f23b9-5056-451e-f718-f92ea4bc80a3","executionInfo":{"status":"ok","timestamp":1564548956222,"user_tz":-540,"elapsed":589,"user":{"displayName":"IkJong P","photoUrl":"https://lh5.googleusercontent.com/-XMHI3In5VGY/AAAAAAAAAAI/AAAAAAAATWk/u_tsKGQQW3I/s64/photo.jpg","userId":"13049101358773066030"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cifar_net = DiyCNN().to(device) # 생성한 뉴럴넷 Instance를 생성하고 빠른 학습을 위해 cuda 에 올립니다. \n","criterion = nn.CrossEntropyLoss() # Loss Function을 정의 합니다. 여기서는 cross entrophy loss 를 사용합니다. \n","optimizer = optim.Adam(cifar_net.parameters(), lr=lr) # optimizer는 이와 같이 training 할 Parameter와 learning rate를 인자로 줍니다. \n","\n","print('[info] number of model parameter - %d'%(count_parameters(cifar_net))) # 방금 구성한 모형의 파라미터 개수를 프린트 해봅니다."],"execution_count":0,"outputs":[{"output_type":"stream","text":["[info] number of model parameter - 3811338\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"J0OFFnddz4CS","colab_type":"code","outputId":"7b4d2bf3-754d-485d-831f-283b4082e22b","executionInfo":{"status":"ok","timestamp":1564549040630,"user_tz":-540,"elapsed":81601,"user":{"displayName":"IkJong P","photoUrl":"https://lh5.googleusercontent.com/-XMHI3In5VGY/AAAAAAAAAAI/AAAAAAAATWk/u_tsKGQQW3I/s64/photo.jpg","userId":"13049101358773066030"}},"colab":{"base_uri":"https://localhost:8080/","height":298}},"source":["train_network(cifar_net,optimizer,trainloader)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[1,   100] loss: 1.753\n","[1,   200] loss: 1.500\n","[1,   300] loss: 1.357\n","[2,   100] loss: 1.183\n","[2,   200] loss: 1.131\n","[2,   300] loss: 1.065\n","[3,   100] loss: 0.977\n","[3,   200] loss: 0.947\n","[3,   300] loss: 0.911\n","[4,   100] loss: 0.864\n","[4,   200] loss: 0.826\n","[4,   300] loss: 0.831\n","[5,   100] loss: 0.759\n","[5,   200] loss: 0.778\n","[5,   300] loss: 0.763\n","Finished Training\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Q27tKqAuz4tM","colab_type":"code","outputId":"1d78e6c3-fc23-435c-d40f-620bc029a023","executionInfo":{"status":"ok","timestamp":1564549073705,"user_tz":-540,"elapsed":2646,"user":{"displayName":"IkJong P","photoUrl":"https://lh5.googleusercontent.com/-XMHI3In5VGY/AAAAAAAAAAI/AAAAAAAATWk/u_tsKGQQW3I/s64/photo.jpg","userId":"13049101358773066030"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["test(cifar_net,testloader)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","Test set:  Accuracy: 7589/10000 (76%)\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"T-UID3Msy1L4","colab_type":"text"},"source":["### 데이터 intialization"]},{"cell_type":"code","metadata":{"id":"yyzEg2_y08-C","colab_type":"code","colab":{}},"source":["class DiyCNN(nn.Module):\n","  def __init__(self):\n","    super(DiyCNN, self).__init__()\n","    layers = []\n","\n","    layers += [nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=2, padding=1)] # 첫 conv는 보통 receptive field를 최대한 넓혀준 후 feature를 뽑아줍니다.\n","    layers += [nn.BatchNorm2d(64)] # 앞선 MLP 시간과 달리 spatial resolution이 살아있기 때문에, batchnorm 2d를 사용해 줍니다.\n","    layers += [nn.ReLU()]\n","    \n","    layers += [nn.Conv2d(64, 128, 3, 2, 1)]\n","    layers += [nn.BatchNorm2d(128)]\n","    layers += [nn.ReLU()]\n","    \n","    layers += [nn.Conv2d(128, 256, 3, 2, 1)]\n","    layers += [nn.BatchNorm2d(256)]\n","    layers += [nn.ReLU()]\n","    \n","    layers += [nn.Conv2d(256, 512, 3, 2, 1)]\n","    layers += [nn.BatchNorm2d(512)]\n","    layers += [nn.ReLU()]\n","    \n","    layers += [nn.AdaptiveAvgPool2d(1)]\n","    \n","    layers += [nn.Conv2d(512, 10, 1, 1, 0)]\n","    \n","    self.main = nn.Sequential(*layers)\n","    self._reset_params() # 실제로 initialize하는 부분 ... self.main에는 layer들이 들어가있다.\n","  def _reset_params(self): # Initialization 을 정의하는 부분 ... 케이스케이스 마다! Gausian or Xavier\n","    for i,layer in enumerate(self.main):\n","      if type(layer) == nn.Conv2d:\n","        torch.nn.init.xavier_uniform_(layer.weight.data)\n","  def forward(self, x):\n","    return self.main(x).squeeze(3).squeeze(2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TbFjh1PL1cJg","colab_type":"code","colab":{}},"source":["cifar_net = DiyCNN().to(device) # 생성한 뉴럴넷 Instance를 생성하고 빠른 학습을 위해 cuda 에 올립니다. \n","criterion = nn.CrossEntropyLoss() # Loss Function을 정의 합니다. 여기서는 cross entrophy loss 를 사용합니다. \n","optimizer = optim.Adam(cifar_net.parameters(), lr=lr) # optimizer는 이와 같이 training 할 Parameter와 learning rate를 인자로 줍니다."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tqshiap61eT8","colab_type":"code","outputId":"3b1d1800-de4f-4bce-c7b3-277a7970b910","colab":{"base_uri":"https://localhost:8080/","height":298},"executionInfo":{"status":"ok","timestamp":1564709882996,"user_tz":-540,"elapsed":149187,"user":{"displayName":"IkJong P","photoUrl":"https://lh5.googleusercontent.com/-XMHI3In5VGY/AAAAAAAAAAI/AAAAAAAATWk/u_tsKGQQW3I/s64/photo.jpg","userId":"13049101358773066030"}}},"source":["train_network(cifar_net,optimizer,trainloader)"],"execution_count":27,"outputs":[{"output_type":"stream","text":["[1,   100] loss: 1.747\n","[1,   200] loss: 1.495\n","[1,   300] loss: 1.408\n","[2,   100] loss: 1.234\n","[2,   200] loss: 1.187\n","[2,   300] loss: 1.137\n","[3,   100] loss: 1.061\n","[3,   200] loss: 1.036\n","[3,   300] loss: 1.012\n","[4,   100] loss: 0.939\n","[4,   200] loss: 0.930\n","[4,   300] loss: 0.894\n","[5,   100] loss: 0.851\n","[5,   200] loss: 0.854\n","[5,   300] loss: 0.843\n","Finished Training\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9y5LmO0S1hHs","colab_type":"code","outputId":"4330b476-bbbe-4278-efcd-2519dbfc0bf1","colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["test(cifar_net,testloader)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","Test set:  Accuracy: 7350/10000 (74%)\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ACfwmSHo1pUW","colab_type":"text"},"source":["weight intialization은 효과가 있었나요?"]},{"cell_type":"markdown","metadata":{"id":"t1gj-ahZvtOK","colab_type":"text"},"source":["### 데이터 전처리를 한번 없애면 성능은 어떻게 변할까요?"]},{"cell_type":"code","metadata":{"id":"XQqpAoljvf2t","colab_type":"code","outputId":"3a4cf108-f0da-4e3c-d2da-15403c24d020","executionInfo":{"status":"ok","timestamp":1564710149797,"user_tz":-540,"elapsed":3198,"user":{"displayName":"IkJong P","photoUrl":"https://lh5.googleusercontent.com/-XMHI3In5VGY/AAAAAAAAAAI/AAAAAAAATWk/u_tsKGQQW3I/s64/photo.jpg","userId":"13049101358773066030"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["# Data\n","print('==> Preparing data..')\n","# 데이터 전처리를 위한 코드 Data augmentation을 제외하고 해보겠다\n","transform_train = transforms.Compose([\n","    \n","    transforms.ToTensor(),\n","     \n","])\n","\n","\n","\n","# 데이터 전처리를 위한 코드\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","   # cifar10(0~1)의 r,g,b 채널 별 평균 및 분산으로 normalization => N(0,1)의 정규분포를 따르도록 만들어준 후 input으로 넣어줍니다.\n","])\n","\n","# 데이터 로딩\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=1)\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=1)\n","\n","classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"],"execution_count":14,"outputs":[{"output_type":"stream","text":["==> Preparing data..\n","Files already downloaded and verified\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ha_j7qGdvztc","colab_type":"code","colab":{}},"source":["cifar_net = DiyCNN().to(device) # 생성한 뉴럴넷 Instance를 생성하고 빠른 학습을 위해 cuda 에 올립니다. \n","criterion = nn.CrossEntropyLoss() # Loss Function을 정의 합니다. 여기서는 cross entrophy loss 를 사용합니다. \n","optimizer = optim.Adam(cifar_net.parameters(), lr=lr) # optimizer는 이와 같이 training 할 Parameter와 learning rate를 인자로 줍니다. "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PYqBc07Qv2rl","colab_type":"code","outputId":"fb3851ff-ae5c-4fdc-85d0-4c50dfdb18e5","executionInfo":{"status":"error","timestamp":1564710226094,"user_tz":-540,"elapsed":69619,"user":{"displayName":"IkJong P","photoUrl":"https://lh5.googleusercontent.com/-XMHI3In5VGY/AAAAAAAAAAI/AAAAAAAATWk/u_tsKGQQW3I/s64/photo.jpg","userId":"13049101358773066030"}},"colab":{"base_uri":"https://localhost:8080/","height":415}},"source":["train_network(cifar_net,optimizer,trainloader)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["[1,   100] loss: 1.567\n","[1,   200] loss: 1.293\n","[1,   300] loss: 1.180\n","[2,   100] loss: 0.968\n","[2,   200] loss: 0.930\n","[2,   300] loss: 0.898\n","[3,   100] loss: 0.715\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-bcd624271182>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcifar_net\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-8-4de130bb6675>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(net, optimizer, trainloader, epochs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m           \u001b[0;31m# print statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m           \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# print every 500 mini-batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m               print('[%d, %5d] loss: %.3f' %\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"dRNdaQCHv3mc","colab_type":"code","outputId":"b44793a4-d883-49a4-8677-aed23e40d9e9","executionInfo":{"status":"ok","timestamp":1564710232668,"user_tz":-540,"elapsed":3485,"user":{"displayName":"IkJong P","photoUrl":"https://lh5.googleusercontent.com/-XMHI3In5VGY/AAAAAAAAAAI/AAAAAAAATWk/u_tsKGQQW3I/s64/photo.jpg","userId":"13049101358773066030"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["test(cifar_net,testloader)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["\n","Test set:  Accuracy: 5675/10000 (57%)\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"P-Y3AkxQ1xe0","colab_type":"text"},"source":["Q) 왜 성능이 낮아졌을까요?\n","\n","data augmentation을 하지 않아서!!"]},{"cell_type":"markdown","metadata":{"id":"j90-Gd4lwyV2","colab_type":"text"},"source":["### 데이터 shuffling 의 효과"]},{"cell_type":"code","metadata":{"id":"Zcon8zppww3H","colab_type":"code","outputId":"08e12b27-b434-45e7-8f2e-a374ace7c06d","colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["# Data\n","print('==> Preparing data..')\n","# 데이터 전처리를 위한 코드\n","transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4), # 4만큼의 padding을 부여한 후, 32x32로 random cropping\n","    transforms.RandomHorizontalFlip(), # 0.5의 확률로 이미지 좌우 반전하여 넣어줌\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), # cifar10(0~1)의 r,g,b 채널 별 평균 및 분산으로 normalization => N(0,1)의 정규분포를 따르도록 만들어준 후 input으로 넣어줍니다.\n","])\n","\n","# 랜덤 cropping을 하고, 이미지 좌우반전을 해주는 이유 : ???\n","\n","# 데이터 전처리를 위한 코드\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), # cifar10(0~1)의 r,g,b 채널 별 평균 및 분산으로 normalization => N(0,1)의 정규분포를 따르도록 만들어준 후 input으로 넣어줍니다.\n","])\n","\n","# 데이터 로딩\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=????, num_workers=1)\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=1)\n","\n","classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["==> Preparing data..\n","Files already downloaded and verified\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pj8oSDzAw68t","colab_type":"code","colab":{}},"source":["cifar_net = DiyCNN().to(device) # 생성한 뉴럴넷 Instance를 생성하고 빠른 학습을 위해 cuda 에 올립니다. \n","criterion = nn.CrossEntropyLoss() # Loss Function을 정의 합니다. 여기서는 cross entrophy loss 를 사용합니다. \n","optimizer = optim.Adam(cifar_net.parameters(), lr=lr) # optimizer는 이와 같이 training 할 Parameter와 learning rate를 인자로 줍니다. "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"J-yaC6mkw9g3","colab_type":"code","outputId":"a3a40899-7941-4156-ed2b-5eed01d04bf3","colab":{"base_uri":"https://localhost:8080/","height":298}},"source":["train_network(cifar_net,optimizer,trainloader)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[1,   100] loss: 1.739\n","[1,   200] loss: 1.488\n","[1,   300] loss: 1.375\n","[2,   100] loss: 1.219\n","[2,   200] loss: 1.155\n","[2,   300] loss: 1.113\n","[3,   100] loss: 1.037\n","[3,   200] loss: 1.013\n","[3,   300] loss: 0.986\n","[4,   100] loss: 0.927\n","[4,   200] loss: 0.913\n","[4,   300] loss: 0.895\n","[5,   100] loss: 0.850\n","[5,   200] loss: 0.834\n","[5,   300] loss: 0.831\n","Finished Training\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4Xgf-jTdw-NY","colab_type":"code","outputId":"6180ce5f-c6d4-4466-a0e1-de34b95643e2","colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["test(cifar_net,testloader)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","Test set:  Accuracy: 7224/10000 (72%)\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MbjVKfzg13q6","colab_type":"text"},"source":["Q) Shuffling 을 제거 했더니 성능이 어떻게 변하나요?  shuffling 은 왜 중요할까요?"]},{"cell_type":"markdown","metadata":{"id":"o19_PEjYxeBM","colab_type":"text"},"source":["### 다시 원래 옵션으로 되돌립니다."]},{"cell_type":"code","metadata":{"id":"XclAWYKSxdH1","colab_type":"code","outputId":"f7ed68cc-7563-4735-dc23-86c6cb33af47","executionInfo":{"status":"ok","timestamp":1562085980824,"user_tz":-540,"elapsed":2742,"user":{"displayName":"Wonwoong Cho","photoUrl":"","userId":"14212918309461362604"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["# Data\n","print('==> Preparing data..')\n","# 데이터 전처리를 위한 코드\n","transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4), # 4만큼의 padding을 부여한 후, 32x32로 random cropping\n","    transforms.RandomHorizontalFlip(), # 0.5의 확률로 이미지 좌우 반전하여 넣어줌\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), # cifar10(0~1)의 r,g,b 채널 별 평균 및 분산으로 normalization => N(0,1)의 정규분포를 따르도록 만들어준 후 input으로 넣어줍니다.\n","])\n","\n","# 랜덤 cropping을 하고, 이미지 좌우반전을 해주는 이유 : ???\n","\n","# 데이터 전처리를 위한 코드\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), # cifar10(0~1)의 r,g,b 채널 별 평균 및 분산으로 normalization => N(0,1)의 정규분포를 따르도록 만들어준 후 input으로 넣어줍니다.\n","])\n","\n","# 데이터 로딩\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=1)\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=1)\n","\n","classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["==> Preparing data..\n","Files already downloaded and verified\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xk0lINI_JMdX","colab_type":"code","colab":{}},"source":["class DiyCNN(nn.Module):\n","  def __init__(self):\n","    super(DiyCNN, self).__init__()\n","    layers = []\n","\n","    layers += [nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=2, padding=1)] # 첫 conv는 보통 receptive field를 최대한 넓혀준 후 feature를 뽑아줍니다.\n","    layers += [nn.BatchNorm2d(64)] # 앞선 MLP 시간과 달리 spatial resolution이 살아있기 때문에, batchnorm 2d를 사용해 줍니다.\n","    layers += [nn.ReLU()]\n","    \n","    layers += [nn.Conv2d(64, 128, 3, 2, 1)]\n","    layers += [nn.BatchNorm2d(128)]\n","    layers += [nn.ReLU()]\n","    \n","    layers += [nn.Conv2d(128, 256, 3, 2, 1)]\n","    layers += [nn.BatchNorm2d(256)]\n","    layers += [nn.ReLU()]\n","    \n","    layers += [nn.Conv2d(256, 512, 3, 2, 1)]\n","    layers += [nn.BatchNorm2d(512)]\n","    layers += [nn.ReLU()]\n","    \n","    layers += [nn.AdaptiveAvgPool2d(1)]\n","    \n","    layers += [nn.Conv2d(512, 10, 1, 1, 0)]\n","    \n","    self.main = nn.Sequential(*layers)\n","    \n","  def forward(self, x):\n","    return self.main(x).squeeze(3).squeeze(2)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yODwdqQEHIGz","colab_type":"text"},"source":["### Learning rate scheduler를 도입합니다. "]},{"cell_type":"code","metadata":{"id":"Xt5HHvczIZIQ","colab_type":"code","colab":{}},"source":["def train_network2(net,optimizer,trainloader, scheduler, epochs=5):\n","  for epoch in range(epochs):  # loop over the dataset multiple times\n","\n","      running_loss = 0.0 # running loss를 저장하기 위한 변수입니다. \n","      for i, data in enumerate(trainloader): # 한 Epoch 만큼 돕니다. 매 iteration 마다 정해진 Batch size 만큼 데이터를 뱉습니다. \n","          # get the inputs\n","          inputs, labels = data # DataLoader iterator의 반환 값은 input_data 와 labels의 튜플 형식입니다. \n","          inputs = inputs.to(device) # Pytorch에서 nn.Module 에 넣어 Backprop을 계산 하기 위해서는 gpu 연동을 이와 같이 해줘야 합니다.\n","          labels = labels.to(device)\n","          # zero the parameter gradients\n","          optimizer.zero_grad()    #  현재 기존의 backprop을 계산하기 위해서 저장했던 activation buffer 를 비웁니다.\n","          # forward + backward + optimize\n","          outputs = net(inputs) # input 을 넣은 위 network 로 부터 output 을 얻어냅니다. \n","          loss = criterion(outputs, labels) # loss fucntion에 주어진 target과 output 의 score를 계산하여 반환합니다. \n","          loss.backward() # * Scalar Loss value를 Backward() 해주게 되면 주어진 loss값을 바탕으로 backpropagation이 진행됩니다. \n","          optimizer.step() # 계산된 Backprop 을 바탕으로 optimizer가 gradient descenting 을 수행합니다. \n","\n","          # print statistics\n","          running_loss += loss.item()\n","          if (i+1) % 100 == 0:    # print every 500 mini-batches\n","              print('[%d, %5d] loss: %.3f' %\n","                    (epoch + 1, i + 1, running_loss / 100))\n","              running_loss = 0.0\n","      scheduler.step() \n","  print('Finished Training')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6OYIUWkQHHgQ","colab_type":"code","outputId":"e0d590c1-737c-48c3-9feb-d9c9a35f7d79","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1564710304237,"user_tz":-540,"elapsed":1412,"user":{"displayName":"IkJong P","photoUrl":"https://lh5.googleusercontent.com/-XMHI3In5VGY/AAAAAAAAAAI/AAAAAAAATWk/u_tsKGQQW3I/s64/photo.jpg","userId":"13049101358773066030"}}},"source":["from torch.optim.lr_scheduler import MultiStepLR\n","\n","scheduler = MultiStepLR(optimizer, milestones=[2,4], gamma=0.5)# mile stone에 해당하는 에폭마다 learning rate을 gamma만큼 줄입니다.\n","##정답은 없고 data, task마다 다 다르다. 그래서 선행연구를 보고 해라 ... milestones는 이정표! gamma를 수정할 epoch수! for문을 어캐 \n","cifar_net = DiyCNN().to(device)\n","criterion = nn.CrossEntropyLoss() \n","optimizer = optim.Adam(cifar_net.parameters(), lr=0.001) # 초반 learning rate이 0.1입니다\n","\n","print('[info] number of model parameter - %d'%(count_parameters(cifar_net))) # 방금 구성한 모형의 파라미터 개수를 프린트 해봅니다."],"execution_count":20,"outputs":[{"output_type":"stream","text":["[info] number of model parameter - 1558026\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"P90jBCr9I1Zx","colab_type":"code","outputId":"991361fe-c2e9-487b-f155-eb79a3c0e472","colab":{"base_uri":"https://localhost:8080/","height":415},"executionInfo":{"status":"error","timestamp":1564710474748,"user_tz":-540,"elapsed":70213,"user":{"displayName":"IkJong P","photoUrl":"https://lh5.googleusercontent.com/-XMHI3In5VGY/AAAAAAAAAAI/AAAAAAAATWk/u_tsKGQQW3I/s64/photo.jpg","userId":"13049101358773066030"}}},"source":["train_network2(cifar_net,optimizer,trainloader, scheduler, epochs=5)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["[1,   100] loss: 1.595\n","[1,   200] loss: 1.288\n","[1,   300] loss: 1.158\n","[2,   100] loss: 0.923\n","[2,   200] loss: 0.889\n","[2,   300] loss: 0.897\n","[3,   100] loss: 0.699\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-78fe40a6a6de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_network2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcifar_net\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-19-38f42bfa9ee9>\u001b[0m in \u001b[0;36mtrain_network2\u001b[0;34m(net, optimizer, trainloader, scheduler, epochs)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m           \u001b[0;31m# print statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m           \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# print every 500 mini-batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m               print('[%d, %5d] loss: %.3f' %\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"C1gRZluHJq8V","colab_type":"code","outputId":"88a5da29-ff9e-44e3-afb2-b31114f0a227","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1564710479522,"user_tz":-540,"elapsed":3689,"user":{"displayName":"IkJong P","photoUrl":"https://lh5.googleusercontent.com/-XMHI3In5VGY/AAAAAAAAAAI/AAAAAAAATWk/u_tsKGQQW3I/s64/photo.jpg","userId":"13049101358773066030"}}},"source":["test(cifar_net,testloader)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["\n","Test set:  Accuracy: 6533/10000 (65%)\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6umQIX-Urwyn","colab_type":"text"},"source":["### Pre-trained 모형 가지고 와서 성능 확인하기 (Transfer Learning 관점)"]},{"cell_type":"code","metadata":{"id":"JecQ-Fkmxjk1","colab_type":"code","outputId":"9e4a7569-019e-49e3-a007-c85a55633e6b","executionInfo":{"status":"ok","timestamp":1564710662515,"user_tz":-540,"elapsed":8721,"user":{"displayName":"IkJong P","photoUrl":"https://lh5.googleusercontent.com/-XMHI3In5VGY/AAAAAAAAAAI/AAAAAAAATWk/u_tsKGQQW3I/s64/photo.jpg","userId":"13049101358773066030"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["import torchvision.models as models ##pytorch 공식 홈페이지에서 가져오겠다.\n","vgg_model = models.vgg19_bn(pretrained=True).to(device) # 기존에 만들어진 vgg network 을 이미지넷 데이터에 트레이닝해둔 파라미터를 그대로 받아옵니다.\n","##pre trained(vgg)에 쓸 weight를 다운 받은 것!"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/vgg19_bn-c79401a0.pth\" to /root/.cache/torch/checkpoints/vgg19_bn-c79401a0.pth\n","100%|██████████| 574769405/574769405 [00:05<00:00, 104563096.77it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"hzItxH6lJRUs","colab_type":"code","outputId":"81a52882-eeb0-4b80-cbc0-9764ac4a87bc","executionInfo":{"status":"ok","timestamp":1562085640589,"user_tz":-540,"elapsed":1307,"user":{"displayName":"Wonwoong Cho","photoUrl":"","userId":"14212918309461362604"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["vgg_model"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace)\n","    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU(inplace)\n","    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (9): ReLU(inplace)\n","    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (12): ReLU(inplace)\n","    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (16): ReLU(inplace)\n","    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (19): ReLU(inplace)\n","    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (22): ReLU(inplace)\n","    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (25): ReLU(inplace)\n","    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (29): ReLU(inplace)\n","    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (32): ReLU(inplace)\n","    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (35): ReLU(inplace)\n","    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (38): ReLU(inplace)\n","    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (42): ReLU(inplace)\n","    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (45): ReLU(inplace)\n","    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (48): ReLU(inplace)\n","    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (51): ReLU(inplace)\n","    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace)\n","    (2): Dropout(p=0.5)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace)\n","    (5): Dropout(p=0.5)\n","    (6): Linear(in_features=4096, out_features=1000, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":54}]},{"cell_type":"code","metadata":{"id":"ofQJ3YcwFqvi","colab_type":"code","colab":{}},"source":["class DiyCNN(nn.Module): ##pre-trained는 image net으로 학습을 시킨 것!\n","    def __init__(self, vgg_model):\n","        super(DiyCNN, self).__init__()\n","        self.pre_trained = nn.Sequential(   \n","            *list(vgg_model.features.children()) # vgg_model의 features에 있는 모든 레이어 (children)들을 차례로 가져와서 붙여줍니다.\n","        ) # 128 x 512 x 1 x 1\n","        \n","        ## FC를 하기전에 잘라버려야 한다. 그래서 features안에 아이들만 가지고 와야한다!\n","        \n","        self.mlp = nn.Sequential(  # 기존에는 이미지넷에 학습되어있기 때문에, 이를 cifar-10 데이터셋용으로 바꿔줄 필요가 있습니다. \n","            nn.Linear(512, 512),   # 따라서 1000이 아닌 10가지의 클래스만을 대상으로 하는 linear 레이어를 새로 쌓고 학습시켜주는부분입니다.\n","            nn.ReLU(),\n","            nn.Linear(512, 128),\n","            nn.ReLU(),\n","            nn.Linear(128, 10),\n","            ## 정보를 계속 줄여나가는 과정!\n","        )\n","    def forward(self, x):\n","        out = self.pre_trained(x) # 128x512x1x1\n","        out = out.squeeze()\n","        out = self.mlp(out)\n","        return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"y6tyTU-3yGHz","colab_type":"code","outputId":"ec09e442-f584-49e3-ecf8-e957fc596e6a","executionInfo":{"status":"ok","timestamp":1564710971694,"user_tz":-540,"elapsed":1485,"user":{"displayName":"IkJong P","photoUrl":"https://lh5.googleusercontent.com/-XMHI3In5VGY/AAAAAAAAAAI/AAAAAAAATWk/u_tsKGQQW3I/s64/photo.jpg","userId":"13049101358773066030"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cifar_net = DiyCNN(vgg_model).to(device)\n","criterion = nn.CrossEntropyLoss() # Loss Function을 정의 합니다. 여기서는 cross entrophy loss 를 사용합니다. \n","optimizer = optim.Adam(cifar_net.parameters(), lr=lr) # optimizer는 이와 같이 training 할 Parameter와 learning rate를 인자로 줍니다. \n","\n","print('[info] number of model parameter - %d'%(count_parameters(cifar_net))) # 방금 구성한 모형의 파라미터 개수를 프린트 해봅니다.\n","##파라미터가 10배 이상으로 늘어버림\n","## pre-trained model을 썻다는 것 자체에서 엄청 성능이 좋아져버림"],"execution_count":27,"outputs":[{"output_type":"stream","text":["[info] number of model parameter - 20365002\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Pro0ncYIyJLg","colab_type":"code","outputId":"592ccb9d-80ed-483e-83bf-e28ff76c5d38","executionInfo":{"status":"ok","timestamp":1564711205422,"user_tz":-540,"elapsed":232866,"user":{"displayName":"IkJong P","photoUrl":"https://lh5.googleusercontent.com/-XMHI3In5VGY/AAAAAAAAAAI/AAAAAAAATWk/u_tsKGQQW3I/s64/photo.jpg","userId":"13049101358773066030"}},"colab":{"base_uri":"https://localhost:8080/","height":87}},"source":["train_network(cifar_net,optimizer,trainloader, epochs=1)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["[1,   100] loss: 1.166\n","[1,   200] loss: 0.795\n","[1,   300] loss: 0.707\n","Finished Training\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Cp7hPPEjyLX6","colab_type":"code","outputId":"f517d0e0-5554-4ccd-e8ba-ec22d8fb72e6","executionInfo":{"status":"ok","timestamp":1564712010025,"user_tz":-540,"elapsed":5640,"user":{"displayName":"IkJong P","photoUrl":"https://lh5.googleusercontent.com/-XMHI3In5VGY/AAAAAAAAAAI/AAAAAAAATWk/u_tsKGQQW3I/s64/photo.jpg","userId":"13049101358773066030"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["test(cifar_net,testloader)"],"execution_count":29,"outputs":[{"output_type":"stream","text":["\n","Test set:  Accuracy: 7777/10000 (78%)\n","\n"],"name":"stdout"}]}]}