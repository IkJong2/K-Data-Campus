{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"20190729_박종익_한국영화리뷰.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"vHMwfNqm9dC3","colab_type":"text"},"source":["## 한국어 영화 리뷰 분석\n","\n","200개 영화 리뷰 100개씩을 가져온 데이터\n","\n","1~10점까지의 평점\n","\n","중립(5-8)은 제외, (1-4)는 긍정, (9-10)은 부정"]},{"cell_type":"code","metadata":{"id":"Aj9kif_JiP69","colab_type":"code","colab":{}},"source":["!git clone https://github.com/e9t/nsmc.git\n","  ##파일에 생긴다! 깃 꺼를 업로드할 때 이런식으로~"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dn8Hyncyh5XL","colab_type":"code","colab":{}},"source":["!cat ./nsmc/ratings_train.txt | head -n 10\n","##id 는 sentence에 대한 고유 id\n","## 라벨은 0이면 부정, 1이면 긍정 ... 조금의 오류는 존재..."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FMi7u129iBQb","colab_type":"code","colab":{}},"source":["with open(\"./nsmc/ratings_train.txt\", \"r\") as f:\n","  file = []\n","  for s in f:\n","    file.append(s.strip().split('\\t'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4BdInnAjlDeW","colab_type":"code","colab":{}},"source":["file[:10]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iYS36L02n1Hy","colab_type":"code","colab":{}},"source":["import pandas as pd"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bnD5sXm5nw_B","colab":{}},"source":["train = pd.read_csv(\"./nsmc/ratings_train.txt\",sep='\\t')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"TM3SSKuVnw_J","colab":{}},"source":["train.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7X2MNxR6jlYk","colab_type":"code","colab":{}},"source":["\"\"\"\n","def read_data(filename):\n","  ##파일 오픈\n","  ##내가 원하는 리스트 형식 처리해주는 code\n","  with open(filename,'r') as f:\n","    data = []\n","    for line in f:\n","      data.append(line.strip().split('\\t'))\n","    data = data[1:]\n","  return data\n","  \"\"\"\n","##구데기.... 다른 함수로 바꾸자!"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8FXChsZG8E1D","colab_type":"code","colab":{}},"source":["with open(\"./nsmc/ratings_train.txt\", 'r') as f:\n","  data = [line.split('\\t') for line in f.read().splitlines()]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4oj0beLy9BAd","colab_type":"code","colab":{}},"source":["data[:3]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tYH4nMkS9KPW","colab_type":"code","colab":{}},"source":["def read_data(filename):\n","  with open(filename,'r') as f:\n","    data = [line.split('\\t') for line in f.read().splitlines()]\n","\n","    data = data[1:]\n","  return data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PGjlZpAljmDJ","colab_type":"code","colab":{}},"source":["train_data = read_data(\"./nsmc/ratings_train.txt\")\n","test_data = read_data(\"./nsmc/ratings_test.txt\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UQth2cbWmASc","colab_type":"code","colab":{}},"source":["train_data[:10]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xo-LptRVmqYG","colab_type":"code","colab":{}},"source":["len(train_data), len(train_data[0]),len(test_data), len(test_data[0]),"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Z0bX_DDoFZO","colab_type":"code","colab":{}},"source":["!pip install konlpy"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uwHyzQpfn-XL","colab_type":"code","colab":{}},"source":["import konlpy\n","konlpy.__version__"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"C08Uc0mboCZD","colab_type":"code","colab":{}},"source":["from konlpy.tag import Okt\n","\n","okt = Okt()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OUvLD7daoikJ","colab_type":"code","colab":{}},"source":["train_data = train_data[:10000]\n","test_data = test_data[:10000]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LbYXuHqHoobJ","colab_type":"code","colab":{}},"source":["okt.pos(train_data[0][1], norm = True, stem=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5y9nZp_4pCn1","colab_type":"code","colab":{}},"source":["\"\"\"\n","def tan_a(data):\n","  tag=[]\n","  for i in range(0,len(data)):\n","    tag.append(okt.pos(data[i][1], norm=True, stem=True))\n","    \n","  return tag\n","  \"\"\"\n","##이 또한 구데기..."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y82vJLeVuFhf","colab_type":"code","colab":{}},"source":["def tokenize(doc):\n","  ##norm은 정규화, stem은 근어로 표시하기를 나타냄\n","  return ['/'.join(t) for t in okt.pos(doc, norm=True, stem=True)]\n","## / 는 품사랑 구분 짓기 위해서 리스트로 되어 있으니까 조인을 시키겠다~"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZDw1hSMT_G0R","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"94963a6e-0645-4e1f-8a0f-6ce22a83981d","executionInfo":{"status":"ok","timestamp":1564391278346,"user_tz":-540,"elapsed":915,"user":{"displayName":"IkJong P","photoUrl":"https://lh5.googleusercontent.com/-XMHI3In5VGY/AAAAAAAAAAI/AAAAAAAATWk/u_tsKGQQW3I/s64/photo.jpg","userId":"13049101358773066030"}}},"source":["train_data[0]"],"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['9976970', '아 더빙.. 진짜 짜증나네요 목소리', '0']"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"code","metadata":{"id":"CZjH-AEf-uyh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"53676e46-0137-4612-a5b1-ef46bd4c49c6","executionInfo":{"status":"ok","timestamp":1564391286266,"user_tz":-540,"elapsed":838,"user":{"displayName":"IkJong P","photoUrl":"https://lh5.googleusercontent.com/-XMHI3In5VGY/AAAAAAAAAAI/AAAAAAAATWk/u_tsKGQQW3I/s64/photo.jpg","userId":"13049101358773066030"}}},"source":["tokenize(train_data[0][1])"],"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['아/Exclamation',\n"," '더빙/Noun',\n"," '../Punctuation',\n"," '진짜/Noun',\n"," '짜증나다/Adjective',\n"," '목소리/Noun']"]},"metadata":{"tags":[]},"execution_count":53}]},{"cell_type":"code","metadata":{"id":"Q7DZBex1qO7R","colab_type":"code","colab":{}},"source":["def make_token(doc):\n","  return ['/'.join(t) \n","          for data in doc\n","          for t in okt.pos(data[1], norm=True, stem=True)\n","          ]\n","# 함수만들기 -okt 이용해서 형태소분석 할 수 있도록 okt.pos 사용\n","# 이 함수를 이용해서 tokenize가 되도록 작성!"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GO5HyaQvpsn0","colab_type":"code","colab":{}},"source":["train_pos = tokenize(train_data)\n","test_pos = tokenize(test_data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"C55IbBB5q-_x","colab_type":"code","colab":{}},"source":["import json\n","import os\n","from pprint import pprint\n","\n","def tokenize(doc):\n","  ##norm은 정규화, stem은 근어로 표시하기를 나타냄\n","  return ['/'.join(t) for t in okt.pos(doc, norm=True, stem=True)]\n","\n","# 함수만들기 -okt 이용해서 형태소분석 할 수 있도록 okt.pos 사용\n","# 이 함수를 이용해서 tokenize가 되도록 작성!\n","\n","if os.path.isfile(\"./nsmc/train_doc.json\"):\n","  with open(\"./nsmc/train_doc.json\") as f:\n","    train_docs = json.load(f)\n","    \n","  with open(\"./nsmc.test_doc.json\") as f:\n","    test_docs = json.load(f)\n","    \n","else : \n","  #train_data에 있는걸 한줄 씩 받아서 리스트로 만들기\n","  train_docs = [(tokenize(row[1]), row[2]) for row in train_data]\n","  test_docs = [(tokenize(row[1]), row[2]) for row in test_data]\n","  \n","  with open(\"./nsmc/train_doc.json\",'w', encoding='utf-8') as make_file:\n","    json.dump(train_docs, make_file, ensure_ascii=False, indent='\\t')\n","  \n","  with open(\"./nsmc/test_doc.json\",'w', encoding='utf-8') as make_file:\n","    json.dump(test_docs, make_file, ensure_ascii=False, indent='\\t')\n","    \n","##if 파일이 있다면, 읽은 다음에 json파일로 생성\n","##else train, test파일을 tokenize함수를 적용하고, json파일로 저장"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"K1Byw-ReoZNR","colab_type":"code","colab":{}},"source":["pprint(train_docs[:2])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JxdIJm7PwdAA","colab_type":"code","colab":{}},"source":["tokens = [t for d in train_docs for t in d[0]]\n","print(len(tokens))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FOSqBVN5xpxu","colab_type":"code","colab":{}},"source":["import nltk\n","text= nltk.Text(tokens, name=\"NMSC\")\n","print(text)\n","##id 값을 주기 위해 nltk를 이용!"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wEh2qfcxx6dl","colab_type":"code","colab":{}},"source":["print(len(text.tokens))\n","##결국 15만개!"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fVKSWW28yA3D","colab_type":"code","colab":{}},"source":["print(len(set(text.tokens)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GRQ_hOO8yDWF","colab_type":"code","colab":{}},"source":["pprint(text.vocab().most_common(10))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bOCAarljyHEL","colab_type":"code","colab":{}},"source":["##10000개 만을 가지고 사전만들기!\n","\n","# 상위 10000개 token을 벡터화시킴\n","selected_words = [f[0] for f in text.vocab().most_common(10000)]\n","\n","# Bag of words를 이용하여 count vector를 만드는 함수\n","# 결국은 빈도세기 위해서!!\n","def term_frequency(doc):\n","  return [doc.count(word) for word in selected_words]\n","\n","\n","# x에는 count vecto가 적용된 문장을\n","# y에서는 정답 셋을\n","train_x = [term_frequency(d) for d, _ in train_docs]\n","test_x = [term_frequency(d) for d, _ in test_docs]\n","train_y = [c for _, c in train_docs]\n","test_y = [c for _, c in test_docs]\n","\n","# train의 라벨은 숨긴다!! 왜냐하면 비교하기 위해"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-YMEg6Wuzv6L","colab_type":"code","colab":{}},"source":["selected_words[:100]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AGz3YrO5yttJ","colab_type":"code","colab":{}},"source":["import numpy as np\n","x_train = np.asarray(train_x).astype('float32')\n","x_test = np.asarray(test_x).astype('float32')\n","y_train = np.asarray(train_y).astype('float32')\n","y_test = np.asarray(test_y).astype('float32')\n","##이렇게 데이터를 float로 바꿔주면 데이터 전처리는 끝!!"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PgyyhrR_zd8A","colab_type":"text"},"source":["Unit : 신경망 데이터를 얼마나 복잡하게 할 것인가?\n","\n","몇 개의 layer를 사용할 것인가??\n","\n","pdf확인하기!"]},{"cell_type":"code","metadata":{"id":"eLzqzPgJzl87","colab_type":"code","colab":{}},"source":["from tensorflow.keras import models\n","from tensorflow.keras import layers\n","from tensorflow.keras import optimizers\n","from tensorflow.keras import losses\n","from tensorflow.keras import metrics\n","model = models.Sequential()\n","model.add(layers.Dense(64, activation='relu',\n","input_shape=(10000,)))\n","model.add(layers.Dense(64, activation='relu'))\n","model.add(layers.Dense(1, activation='sigmoid'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0eMnDXBZ0P8q","colab_type":"code","colab":{}},"source":["# 손실 함수로는 binary_crossentropy를 사용\n","# RMSProp 옵티마이저를 통해서 gradient desent을 진행\n","# 또한 배치 사이즈를 512로, 에포크를 10번으로 학습\n","model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n","loss=losses.binary_crossentropy,\n","metrics=[metrics.binary_accuracy])\n","model.fit(x_train, y_train, epochs=10, batch_size=512)\n","results = model.evaluate(x_test, y_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NwjoES4K0SVb","colab_type":"code","colab":{}},"source":["results"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iwDSXYN20ac1","colab_type":"code","colab":{}},"source":["def predict_pos_neg(review):\n","  token = tokenize(review)\n","  tf = term_frequency(token)\n","# 데이터 형태 맞추기 위해 np.expand_dims 메서드를 이용해 array의 축을 확장\n","  data = np.expand_dims(np.asarray(tf).astype('float32'), axis=0)\n","  score = float(model.predict(data))\n","# 최종 확률이 0.5 보다 크면 긍정이고, 그렇지 않으면 부정이라고 예측\n","  if(score > 0.5):\n","    print(\"[{}]는 {:.2f}% 확률로 긍정 리뷰이지 않을까추측해봅니다.^^\\n\"\\\n","          .format(review, score * 100))\n","  else:\n","    print(\"[{}]는 {:.2f}% 확률로 부정 리뷰이지 않을까추측해봅니다.^^;\\n\"\\\n","          .format(review, (1 - score) * 100))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KSA8sMOt0pK2","colab_type":"code","colab":{}},"source":["predict_pos_neg(\"올해 최고의 영화! 세 번 넘게 봐도 질리지가않네요.\")\n","predict_pos_neg(\"배경 음악이 영화의 분위기랑 너무 안맞았습니다. 몰입에 방해가 됩니다.\")\n","predict_pos_neg(\"주연 배우가 신인인데 연기를 진짜 잘 하네요.몰입감 ㅎㄷㄷ\")\n","predict_pos_neg(\"믿고 보는 감독이지만 이번에는 아니네요\")\n","predict_pos_neg(\"주연배우 때문에 봤어요\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ScnY2rEp0qw3","colab_type":"text"},"source":["여기서는 결국 bag of words가 필요했다\n","\n","내가 필요한 json 파일이 없다면 만들어서 생성도 해야하고 있다면 패스도 해야한다.\n","\n","그리고 문제에 맞게 설계를 해야할 것이다."]},{"cell_type":"markdown","metadata":{"id":"B5wXWtLe1ahA","colab_type":"text"},"source":["1. git clone을 통해 데이터를 가져와서 확인을 함\n","2. 파일을 로드해서 데이터를 생성 -> 데이터를 잘 생성했는지 check\n","3. konlpy의 okt를 통해 생성 ...속도가 좋고, 성능도 어느정도 나오고, 신조어 처리가 가능\n","4. tokenize를 실시함! ... 형태소 분석을 통해서 이 문장이 어떤 단어, 어떻게 라벨링이 되어있는지 check하고 json파일 생성! ... if else\n","5. 토크나이즈 bag of words를 위해 전체 토큰을 생성함! ... 하나의 리스트로 생성 ... 리스트로 만든 이유는? 15만개를 봄! \n","6. 그리고 10000개만 뽑아서 senetence에서 word와 매칭되어 있으면 카운트를 실시!\n","7. float로 텐서플로우에 넣기 위해 다시 생성\n","8. layer를 3개 생성 2개는 Lelu, 1개는 Sigmoid ... 01로 하기 위해!\n","9. 그리고 결과를 본다.\n","10. 함수를 이용하여, 긍정.부정 리뷰를 분리함"]},{"cell_type":"code","metadata":{"id":"lbfLb6eo2bee","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}