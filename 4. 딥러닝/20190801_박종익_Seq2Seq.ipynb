{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"20190801_박종익_Seq2Seq.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"5zthtOlIjcO1","colab_type":"text"},"source":["**Copyright(C). Cheonbok Park. All rights reserved.**\n","\n","Email : cb_park@korea.ac.kr"]},{"cell_type":"markdown","metadata":{"id":"CUXuCrrc3AxQ","colab_type":"text"},"source":["- 복잡하지는 않지만 감을 잡는다는 느낌으로 진행하면 됩니당당당당당"]},{"cell_type":"markdown","metadata":{"id":"lWPhKRrqw8Vl","colab_type":"text"},"source":["### 필요 라이브러리 설치"]},{"cell_type":"code","metadata":{"id":"krquphUSw64W","colab_type":"code","colab":{}},"source":["# 필요한 라이브러리를 설치합니다. "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TF6swkROGoRk","colab_type":"code","colab":{}},"source":["import torch # torch library \n","import torch.nn as nn # Nueral Network에 대한 package\n","import numpy as np  # numpy \n","import editdistance # 평가 지표로서 사용될 edit distance \n","import matplotlib.pyplot as plt # plot 을 찍기 위한 라이브러리\n","import tqdm\n","import torch.nn.functional as F # pytorch function 들을 사용하기 위한 용도 \n","from torch.utils import data # dataset 관련된 utility 를 사용하려는 용도\n","from random import choice, randrange # random\n","from itertools import zip_longest \n","import librosa\n","import os   # directory 생성 및 디렉토리 생성과 관련된 package \n","import json \n","import random\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dvgO0Z-3xKpr","colab_type":"text"},"source":["### Data Loader "]},{"cell_type":"markdown","metadata":{"id":"N5VY4V8ifgNm","colab_type":"text"},"source":["![대체 텍스트](https://pytorch.org/tutorials/_images/word-encoding.png)"]},{"cell_type":"code","metadata":{"id":"JPt35iPSs0dO","colab_type":"code","colab":{}},"source":["def batch(iterable, n=1):\n","    args = [iter(iterable)] * n\n","    return zip_longest(*args)\n","\n","\n","def pad_tensor(vec, pad, value=0, dim=0):\n","    \"\"\"\n","    pad token으로 채우는 용도 \n","    args:\n","        vec - tensor to pad\n","        pad - the size to pad to\n","        dim - dimension to pad\n","    return:\n","        a new tensor padded to 'pad' in dimension 'dim'\n","    \"\"\"\n","    pad_size = pad - vec.shape[0]\n","\n","    if len(vec.shape) == 2:\n","        zeros = torch.ones((pad_size, vec.shape[-1])) * value\n","    elif len(vec.shape) == 1:\n","        zeros = torch.ones((pad_size,)) * value\n","    else:\n","        raise NotImplementedError\n","    return torch.cat([torch.Tensor(vec), zeros], dim=dim)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7t-W0gQps2rg","colab_type":"text"},"source":["![대체 텍스트](https://i.stack.imgur.com/Kuhh0.jpg)\n","\n","이런식으로 padding을 주게 되면 메모리를 절약할 수 있음\n","\n","pack padded sequence"]},{"cell_type":"code","metadata":{"id":"QAaKIfA7BdLX","colab_type":"code","colab":{}},"source":["def pad_collate(batch, values=(0, 0), dim=0):\n","    \"\"\"\n","    데이터 로더에 들어가기전에 batch화 할 때 거치는 함수 \n","    args:\n","        batch - list of (tensor, label)\n","    reutrn:\n","        xs - a tensor of all examples in 'batch' after padding\n","        ys - a LongTensor of all labels in batch\n","        ws - a tensor of sequence lengths\n","    \"\"\"\n","\n","    sequence_lengths = torch.Tensor([int(x[0].shape[dim]) for x in batch]) # 각 batch 마다 길이를 얻어내고 \n","    sequence_lengths, xids = sequence_lengths.sort(descending=True) # 감소하는 순서로 정렬\n","    ## xids가 descending order했을 때, index\n","    target_lengths = torch.Tensor([int(x[1].shape[dim]) for x in batch])\n","    # find longest sequence (가장 긴 sequence의 길이를 구함 )\n","    src_max_len = max(map(lambda x: x[0].shape[dim], batch))\n","    tgt_max_len = max(map(lambda x: x[1].shape[dim], batch))\n","    # pad according to max_len (max length 만큼 padd를 추가 )\n","    batch = [(pad_tensor(x, pad=src_max_len, dim=dim), pad_tensor(y, pad=tgt_max_len, dim=dim)) for (x, y) in batch]\n","\n","    # stack all\n","    xs = torch.stack([x[0] for x in batch], dim=0)\n","    ys = torch.stack([x[1] for x in batch], dim=0) ##아직은 descending order로 정렬 X\n","    xs = xs[xids].contiguous() # decreasing order로 다시 나열 \n","    ys = ys[xids].contiguous() # xids 와 같은 순서로 \n","    target_lengths = target_lengths[xids] # same descending order\n","    return xs.long(), ys.long(), sequence_lengths.int(), target_lengths.int()\n","\n","\n","class ToyDataset(data.Dataset):\n","    \"\"\"\n","    https://talbaumel.github.io/blog/attention/\n","    \"\"\"\n","    def __init__(self, min_length=5, max_length=20, type='train'):\n","        self.SOS = \"<s>\"  # all strings will end with the End Of String token )\n","        self.EOS = \"</s>\"  # all strings will end with the End Of String token\n","        self.characters = list(\"abcde\")\n","        self.int2char = list(self.characters)\n","        self.char2int = {c: i+3 for i, c in enumerate(self.characters)} # +3 을 왜하는 가? 토큰 3개라서 추가 start end pad 이 아이들도 번역해야함\n","        print(self.char2int)\n","        self.VOCAB_SIZE = len(self.characters)\n","        self.min_length = min_length\n","        self.max_length = max_length\n","        \n","        # train set or test set 을 생성 \n","        if type == 'train':\n","            self.set = [self._sample() for _ in range(4000)]\n","        else:\n","            self.set = [self._sample() for _ in range(300)]\n","\n","    def __len__(self): ##데이터 셋의 전체 길이를 줘야함! \n","        # 필수 ! \n","        return len(self.set)\n","\n","    def __getitem__(self, item): ##인덱스 기반으로 하여 주게 됨\n","        # 필수 !\n","        return self.set[item]\n","\n","    def _sample(self):\n","        random_length = randrange(self.min_length, self.max_length)  # Pick a random length\n","        random_char_list = [choice(self.characters[:-1]) for _ in range(random_length)]  # Pick random chars\n","        random_string = ''.join(random_char_list)\n","        a = np.array([self.char2int.get(x) for x in random_string]+[2])\n","        b = np.array([self.char2int.get(x) for x in random_string[::-1]] + [2]) # Return the random string and its reverse + EOS \n","        \n","        return a, b\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7QcWCIsJzltc","colab_type":"text"},"source":["### utils misc.py\n","\n"]},{"cell_type":"code","metadata":{"id":"SciyvlCzBe-B","colab_type":"code","colab":{}},"source":["EOS_TOKEN = '</s>'\n","\n","\n","def check_size(tensor, *args):\n","    size = [a for a in args]\n","    assert tensor.size() == torch.Size(size), tensor.size()\n","\n","def to_mono(y):\n","    assert y.ndim == 2\n","    return np.mean(y, axis=1)\n","\n","\n","def edit_distance(guess, truth):\n","    guess = guess.split(EOS_TOKEN)[0]\n","    truth = truth[3:].split(EOS_TOKEN)[0]\n","    return editdistance.eval(guess, truth) / len(truth)\n","\n","\n","class AttrDict(dict):\n","  __getattr__ = dict.__getitem__\n","  __setattr__ = dict.__setitem__"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a0Hv4JFBzM-4","colab_type":"text"},"source":["### Edit distance (편집거리 알고리즘) "]},{"cell_type":"markdown","metadata":{"id":"X4ct9e_OzuTT","colab_type":"text"},"source":["![대체 텍스트](https://raw.githubusercontent.com/sumitc91/data/master/askgif-blog/9e07d056-ccf7-4fc8-b6ee-000c8032b9ec_editDistance.gif)"]},{"cell_type":"code","metadata":{"id":"cwbk7k7h4PKB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"190a89a1-3bdb-4589-d545-faabc49a3827","executionInfo":{"status":"ok","timestamp":1564642071230,"user_tz":-540,"elapsed":1022,"user":{"displayName":"IkJong P","photoUrl":"https://lh5.googleusercontent.com/-XMHI3In5VGY/AAAAAAAAAAI/AAAAAAAATWk/u_tsKGQQW3I/s64/photo.jpg","userId":"13049101358773066030"}}},"source":["# edit distance 란 편집 거리 \n","\n","\n","ref = [1, 2, 3, 4]\n","hyp = [1, 2, 4, 5, 6]\n","editdistance.eval(ref,hyp)"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"C1VtDggGzzs_","colab_type":"text"},"source":["### Attention Mask"]},{"cell_type":"code","metadata":{"id":"BOMNQN6Gj_-p","colab_type":"code","colab":{}},"source":["## 추후에 설명 Decoder section\n","def mask_3d(inputs, seq_len, mask_value=0.):\n","    batches = inputs.size()[0]\n","    assert batches == len(seq_len) # length 체크 \n","    max_idx = max(seq_len) # max length 체크 \n","    for n, idx in enumerate(seq_len): # length 에서 의미없는 hidden state attention 값은 0으로 두기 위한 mask값 설정 \n","        if idx < max_idx.item():\n","            if len(inputs.size()) == 3:\n","                inputs[n, idx.int():, :] = mask_value\n","            else:\n","                assert len(inputs.size()) == 2, \"The size of inputs must be 2 or 3, received {}\".format(inputs.size())\n","                inputs[n, idx.int():] = mask_value\n","    return inputs"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kXtIVGUgHmws","colab_type":"text"},"source":["## Encoder RNN"]},{"cell_type":"markdown","metadata":{"id":"LdFDvktffm9k","colab_type":"text"},"source":["![대체 텍스트](https://pytorch.org/tutorials/_images/encoder-network.png)\n","\n","Computation graph를 만드는 것이 딥러닝 모델링의 시작!"]},{"cell_type":"markdown","metadata":{"id":"Qf62OoGcwJP5","colab_type":"text"},"source":["#### Embedding Module "]},{"cell_type":"markdown","metadata":{"id":"c8mNg3ve8LmT","colab_type":"text"},"source":["![대체 텍스트](https://i.ibb.co/S0NJzq7/embedding.png)"]},{"cell_type":"markdown","metadata":{"id":"kH2OnZrXwOqk","colab_type":"text"},"source":["#### GRU Module"]},{"cell_type":"markdown","metadata":{"id":"goSiSeiq8bn-","colab_type":"text"},"source":["![대체 텍스트](https://i.ibb.co/881BygH/GRU.png)"]},{"cell_type":"markdown","metadata":{"id":"L_TIF6h58dZf","colab_type":"text"},"source":["![대체 텍스트](https://i.ibb.co/NsMqvcH/GRU-param.png)\n","\n","in CNN (B, 3, W, H)\n","\n","in RNN (B, T) if batch_first = True\n","\n","false? -> (T, B) ... time 순서로 찾아가기 때문에~"]},{"cell_type":"markdown","metadata":{"id":"g-Z_vgd2wSAd","colab_type":"text"},"source":["#### ENCODER RNN Code"]},{"cell_type":"code","metadata":{"id":"8d__61m2HfFR","colab_type":"code","colab":{}},"source":["from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","class EncoderRNN(nn.Module):\n","    def __init__(self, config):\n","        super(EncoderRNN, self).__init__()\n","        self.input_size = config[\"n_channels\"]\n","        self.hidden_size = config[\"encoder_hidden\"]\n","        self.layers = config.get(\"encoder_layers\", 1)\n","        \n","        self.dropout = config.get(\"encoder_dropout\", 0.) \n","        self.bi = config.get(\"bidirectional_encoder\", False)\n","        embedding_dim = config.get(\"embedding_dim\", None)\n","        self.embedding_dim = embedding_dim if embedding_dim is not None else self.hidden_size\n","        self.embedding = nn.Embedding(config.get(\"n_classes\", 32), self.embedding_dim, padding_idx=0) ##padding token은 0\n","        gru_input_dim = self.embedding_dim\n","        self.rnn = nn.GRU( ##만약 lstm?? nn.lstm\n","            gru_input_dim,\n","            self.hidden_size,\n","            self.layers,\n","            dropout=self.dropout,\n","            bidirectional=self.bi,\n","            batch_first=True)# model 선언 \n","        self.gpu = config.get(\"gpu\", False) \n","\n","\n","\n","    def forward(self, inputs, hidden, input_lengths): ##레고를 순서대로 나열해야한다~\n","        \n","        # pack padded 를 통하여 input을 감싸기 \n","        inputs = self.embedding(inputs)\n","        \n","        x = pack_padded_sequence(inputs, input_lengths, batch_first=True) # RNN을 메모리적으로 효과적으로 돌리고자! BT순서로 하기위해 batch_first\n","        output, state = self.rnn(x, hidden) ##previous hidden state = initial hidden state\n","        output, _ = pad_packed_sequence(output, batch_first=True, padding_value=0.) # sequence 를 위의 그림과 같이 pack함 pad_packed! 반대이다~\n","        ## batch x input x hidden 인데 batch 를 다 사용하지 않는다!!\n","        \n","        if self.bi: # bidirectional 의 경우 forward와 backward를 sum하여 사용한다. or concat \n","            output = output[:, :, :self.hidden_size] + output[:, :, self.hidden_size:] ##사실 덧셈보다 concat이 더 맞다\n","            state = state[:1] +state[1:]\n","        return output, state\n","\n","    def init_hidden(self, batch_size):\n","        # hidden state가 없는 초기 상태일때 \n","        h0 = torch.zeros(2 if self.bi else 1, batch_size, self.hidden_size)\n","        if self.gpu:\n","            h0 = h0.cuda()\n","        return h0"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aZSYZqWVwM_z","colab_type":"text"},"source":["![대체 텍스트](https://pytorch.org/tutorials/_images/attention-decoder-network.png)"]},{"cell_type":"markdown","metadata":{"id":"l8yDzSXKHnyB","colab_type":"text"},"source":["### Decoder \n","\n","**Decoder는 bidirection을 하.면.안.된.다!!**"]},{"cell_type":"code","metadata":{"id":"X83Lj_GBHojW","colab_type":"code","colab":{}},"source":["class Decoder(nn.Module):\n","    def __init__(self, config):\n","        super(Decoder, self).__init__()\n","        self.batch_size = config[\"batch_size\"]\n","        self.hidden_size = config[\"decoder_hidden\"]\n","        embedding_dim = config.get(\"embedding_dim\", None)\n","        self.embedding_dim = embedding_dim if embedding_dim is not None else self.hidden_size\n","        self.embedding = nn.Embedding(config.get(\"n_classes\", 32), self.embedding_dim, padding_idx=0)\n","        self.rnn = nn.GRU(\n","            input_size=self.embedding_dim+self.hidden_size if config['decoder'].lower() == 'bahdanau' else self.embedding_dim,\n","            hidden_size=self.hidden_size,\n","            num_layers=config.get(\"decoder_layers\", 1),\n","            dropout=config.get(\"decoder_dropout\", 0),\n","            bidirectional=False,\n","            batch_first=True)\n","        if config['decoder'] != \"RNN\":\n","            self.attention = Attention(\n","                self.batch_size,\n","                self.hidden_size,\n","                method=config.get(\"attention_score\", \"dot\"))\n","\n","        self.gpu = config.get(\"gpu\", False)\n","        self.decoder_output_fn = F.log_softmax if config.get('loss', 'NLL') == 'NLL' else None\n","\n","    def forward(self, **kwargs):\n","        \"\"\" Must be overrided \"\"\"\n","        raise NotImplementedError"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jcUzMxqV9Lr2","colab_type":"text"},"source":["![대체 텍스트](https://i.ibb.co/gvpn1RT/bmm.png)"]},{"cell_type":"markdown","metadata":{"id":"CBkw-82hE3MU","colab_type":"text"},"source":["![대체 텍스트](http://cnyah.com/2017/08/01/attention-variants/attention-mechanisms.png)\n","\n","Embedding layer를 맨 아래에 깔아야 할 것이다.\n","\n","RNN을 두개를 쌓을 것! -> bidirection OK! ... RNN에 초기 hidden state를 주어야 할것!! (initial hidden state)\n","\n","Encoder 에서 hidden state를 만들 것!\n","\n","input은 Sentence Batch(token, index)\n","\n","- 필요한 것\n","  - input -> Embedding -> RNN\n","  - previous_hidden -> RNN  ..... RNN에서 통해서 나온게 encoder (hidden) state\n","  \n","\n","- Decoder\n","  - Decoder RNN(초기값이 encoder last hidden_state)해야함! ... embedding 과 RNN을 해야함 input이 decoder token!\n","  - 그리고 Attention model ... encoder hidden state! + RNN 현재 상태의 hidden_state => 유사도 계산!\n","  - dot product를 해주면 logit이 나오고 softmax하고 weight average를 하게 되면 Context vector(결과 벡터)가 만들어짐\n","  \n","  \n","왼쪽 그림은 지금 필요한 것을 가져오고\n","\n","오른쪽 그림은 다음 필요한 것을 가져오게 된다."]},{"cell_type":"code","metadata":{"id":"IYbzCRP6HuLD","colab_type":"code","colab":{}},"source":["class BahdanauDecoder(Decoder): ##모델안에서 for문 쓰는 순간 끝장난다\n","    \"\"\"\n","        Corresponds to BahdanauAttnDecoderRNN in Pytorch tutorial\n","    \"\"\"\n","\n","    def __init__(self, config):\n","        super(BahdanauDecoder, self).__init__(config)\n","        self.output_size = config.get(\"n_classes\", 32)\n","        self.character_distribution = nn.Linear(self.hidden_size, self.output_size)\n","\n","    def forward(self, **kwargs):\n","        \"\"\"\n","        :param input: [B]\n","        :param prev_context: [B, H]\n","        :param prev_hidden: [B, H]\n","        :param encoder_outputs: [B, T, H]\n","        :return: output (B), context (B, H), prev_hidden (B, H), weights (B, T)\n","        \"\"\"\n"," \n","        input = kwargs[\"input\"] # decoder input \n","        prev_hidden = kwargs[\"prev_hidden\"] # decoder rnn 에서 들어갈 previous hidden state \n","        encoder_outputs = kwargs[\"encoder_outputs\"] # encoder RNN에서 Encoding이 끝난 (B,L,hidden_size)  \n","        seq_len = kwargs.get(\"seq_len\", None) # sequence length \n","\n","        # check inputs\n","        \n","       \n","\n","        # Attention weights\n","        weights = self.attention.forward(prev_hidden, encoder_outputs, seq_len)  # B x T ... [B,1,T]\n","        context = weights.unsqueeze(1).bmm(encoder_outputs).squeeze(1)  #[B,1,T] [B,T,H] -> [B x H] ... T가 사라짐 by batch matrix multiple\n","\n","        # embed characters\n","        embedded = self.embedding(input).unsqueeze(0) # (B, Embedding) -> (1, B, Embedding)\n","        \n","        #attention 을 통해 얻어낸 context를 추가하여 모델에 input으로 제공\n","        rnn_input = torch.cat((embedded, context.unsqueeze(0)), 2) # (1, B, Embedding) (1, B, H) -> (1, B, EMB+H)\n","        \n","        #(1, b, emb+h) => .transpose(1,0) -> (b,1,emb+h)\n","        outputs, hidden = self.rnn(rnn_input.transpose(1, 0), prev_hidden.unsqueeze(0)) # 1 x B x N, B x N\n","\n","        #(b, 1, hidden_size) => (b, logits)\n","        output = self.character_distribution(outputs.squeeze(0)) # logit 값 각 chracter 별로\n","\n","        if self.decoder_output_fn:\n","            # NLL loss 인 경우 \n","            output = self.decoder_output_fn(output, -1)\n","\n","        if len(output.size()) == 3:\n","            output = output.squeeze(1)\n","\n","        return output, hidden.squeeze(0), weights\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eHhtZXhUEQ64","colab_type":"text"},"source":["![대체 텍스트](https://i.stack.imgur.com/tiQkz.png)\n","\n","남의 코드를 볼 때에는 옆에 Dimension을 적어가면서 볼 것!\n","===="]},{"cell_type":"code","metadata":{"id":"kYfGqtu0eqZy","colab_type":"code","colab":{}},"source":["class Attention(nn.Module):\n","    \"\"\"\n","    Inputs:\n","        last_hidden: (batch_size, hidden_size)\n","        encoder_outputs: (batch_size, max_time, hidden_size)\n","    Returns:\n","        attention_weights: (batch_size, max_time)\n","    \"\"\"\n","    def __init__(self, batch_size, hidden_size, method=\"dot\"):\n","        super(Attention, self).__init__()\n","        self.method = method\n","        self.hidden_size = hidden_size\n","        if method == 'dot':\n","            pass\n","        elif method == 'general':\n","            # Wa (hidden,hidden)\n","            self.Wa = nn.Linear(hidden_size, hidden_size, bias=False)\n","        elif method == \"concat\":\n","            # Wa : (2*hidden,hidden)\n","            # Va : (hidden,1)\n","            self.Wa = nn.Linear(2*hidden_size, hidden_size, bias=False)\n","            self.va = nn.Parameter(torch.FloatTensor(hidden_size, 1))\n","        elif method == 'bahdanau':\n","            # Wa : (hidden_size,hidden_size) \n","            # Ua : (hidden_size,hidden_size)\n","            # Va : (hidden_size,1)\n","            self.Wa = nn.Linear(hidden_size, hidden_size, bias=False)\n","            self.Ua = nn.Linear(hidden_size, hidden_size, bias=False)\n","            self.va = nn.Parameter(torch.FloatTensor(hidden_size, 1))\n","        else:\n","            raise NotImplementedError\n","\n","        \n","    def forward(self, last_hidden, encoder_outputs, seq_len=None):\n","        \"\"\"\n","        Inputs :\n","          last_hidden : (B,T,hidden_size)\n","          encoder_outputs : \n","          seq_len:  \n","        Returns:\n","          attention matrix : \n","        \"\"\"\n","        batch_size, seq_lens, _ = encoder_outputs.size()\n","        # attention energies 를 구하기 \n","        attention_energies = self._score(last_hidden, encoder_outputs, self.method)\n","        \n","        if seq_len is not None:\n","            attention_energies = mask_3d(attention_energies, seq_len, -float('inf'))\n","\n","        return F.softmax(attention_energies, -1)\n","\n","    def _score(self, last_hidden, encoder_outputs, method):\n","        \"\"\"\n","        Computes an attention score\n","        :param last_hidden: (batch_size, hidden_dim)\n","        :param encoder_outputs: (batch_size, max_time, hidden_dim)\n","        :param method: str (`dot`, `general`, `concat`)\n","        :return:\n","        \"\"\"\n","\n","        # assert last_hidden.size() == torch.Size([batch_size, self.hidden_size]), last_hidden.size()\n","        \n","        if method == 'dot':\n","            last_hidden = last_hidden.unsqueeze(-1) # (batch_size, hidden_dim,1)\n","            \n","            # attention : (batch_size,max_time, hidden_dim) , (batch_size,hidden_dim,1) - > (batch_size,max_time ,1)\n","            \n","            return encoder_output.bmm(last_hidden).squeeze(-1)  \n","\n","        elif method == 'general':\n","            # dot 이랑 비슷 다만 last hidden을 한번 projection\n","            x = self.Wa(last_hidden) # (batch_size, hidden_dim) ->  (batch_size, hidden_dim)\n","            x = x.unsqueeze(-1) # (batch_size, hidden_dim) ->  (batch_size, hidden_dim,1)\n","            # encoded 된 hidden states 와 dot proudct를 수행하기 \n","            # attention: (batch_size,max_time, hidden_dim) , (batch_size,hidden_dim,1) - > (batch_size,max_time ,1)\n","            return encoder_output.bmm(x).squeeze(-1)\n","\n","        elif method == \"concat\":\n","          #encoder_output 은 (B, max_time, hidden_state)  지금은 (B, hidden_state) ... unsqueeze -> (b,1,hidden_size) -> (b, max_time, hidden_state)\n","          \n","            x = last_hidden.unsqueeze(1).expand_as(encoder_outputs) # (batch_size, hidden_dim) ->  (batch_size,1, hidden_dim)\n","            # concat 후 -> linear 거치기 -> 후 tanh\n","            x = F.tanh(self.Wa(torch.cat((x, encoder_outputs), -1))) # (batch_size, max_timestep, hidden_dim) ->  (batch_size,  max_timestep, hidden_dim*2)\n","            # (batch_size, max_timestep, hidden_dim*2) ->  (batch_size,  max_timestep, 1!) => 1을 날려줘야함 => squeeze(1 => (B, max)\n","            return x.matmul(self.va).squeeze(-1)\n","\n","        elif method == \"bahdanau\":\n","            a\n","        else:\n","            raise NotImplementedError"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JqeFcsDJ7Dz2","colab_type":"text"},"source":["### Seq2Seq Model "]},{"cell_type":"markdown","metadata":{"id":"jS2cmY548vtB","colab_type":"text"},"source":["![대체 텍스트](https://i.ibb.co/CK5wTz5/crossentropy.png)"]},{"cell_type":"markdown","metadata":{"id":"z_rIN2DY80pD","colab_type":"text"},"source":["![대체 텍스트](https://i.ibb.co/ssXZ28q/crossentropy-2.png)"]},{"cell_type":"code","metadata":{"id":"V-axgHRo7C5V","colab_type":"code","colab":{}},"source":["class Seq2Seq(nn.Module):\n","    \"\"\"\n","        Sequence to sequence module\n","    \"\"\"\n","\n","    def __init__(self, config):\n","        super(Seq2Seq, self).__init__()\n","        self.SOS = config.get(\"start_index\", 1) # Start index를 가져옵니다. \n","        self.vocab_size = config.get(\"n_classes\", 32) # embedding 에 필요한 vocabulary size \n","        self.batch_size = config.get(\"batch_size\", 1) # batch_size 정보를 가져옵니다.\n","        self.gpu = config.get(\"gpu\", False) # cuda 로 돌아가는지 아닌지에 대한 정보 \n","\n","        # Encoder 선언\n","        \n","        self.encoder = EncoderRNN(config)\n","\n","        # Decoder 선언 \n","        \n","        self.decoder = BahdanauDecoder(config)\n","        \n","        # loss fucntion \n","        # ignore_index =0 왜???\n","        self.loss_fn = torch.nn.CrossEntropyLoss(ignore_index=0)\n","        \n","        \n","\n","    def encode(self, x, x_len):\n","        # encoder를 통해 주어진 source 정보를 Encodeing 하는 용도 \n","        \n","        batch_size = x.size()[0]\n","        # 초기 inital hidden state 만들기\n","        init_state = self.encoder.init_hidden(batch_size)\n","        # encoder Forward 수행 \n","        encoder_outputs, encoder_state = self.encoder.forward(x, init_state, x_len)\n","        \n","        \n","       \n","        return encoder_outputs, encoder_state.squeeze(0)\n","\n","    def decode(self, encoder_outputs, encoder_hidden, targets, targets_lengths, input_lengths):\n","        \"\"\"\n","        Args:\n","            encoder_outputs: (B, T, H)\n","            encoder_hidden: (B, H)\n","            targets: (B, L)\n","            targets_lengths: (B)\n","            input_lengths: (B)\n","        Vars:\n","            decoder_input: (B)\n","            decoder_context: (B, H)\n","            hidden_state: (B, H)\n","            attention_weights: (B, T)\n","        Outputs:\n","            alignments: (L, T, B)\n","            logits: (B*L, V)\n","            labels: (B*L)\n","        \"\"\"\n","\n","        batch_size = encoder_outputs.size()[0]\n","        max_length = targets.size()[1]\n","        # decoder의 처음 y0 는 무엇이 되어야 할까? *주의해야할 포인트 \n","        if batch_size ==1:\n","          decoder_input = torch.LongTensor([self.SOS] * batch_size)\n","        else:\n","          decoder_input = torch.LongTensor([self.SOS] * batch_size).squeeze(-1)\n","        decoder_context = encoder_outputs.transpose(1, 0)[-1] #(Batch,1)\n","        decoder_hidden = encoder_hidden\n","        \n","        #alignments :  attention align을 저장하기 위한 용도  \n","        alignments = torch.zeros(max_length, encoder_outputs.size(1), batch_size) # attention align을 저장하기 위한 용도 \n","        logits = torch.zeros(max_length, batch_size, self.decoder.output_size) # logits 값을 저장하기 위한 용도의 tensor \n","\n","        if self.gpu:\n","            decoder_input = decoder_input.cuda()\n","            decoder_context = decoder_context.cuda()\n","            logits = logits.cuda()\n","        inference = []\n","        for t in range(max_length):\n","\n","            # The decoder accepts, at each time step t :\n","            # - an input, [B]\n","            # - a context, [B, H]\n","            # - an hidden state, [B, H]\n","            # - encoder outputs, [B, T, H]\n","            \n","            # The decoder outputs, at each time step t :\n","            # - an output, [B]\n","            # - a context, [B, H]\n","            # - an hidden state, [B, H]\n","            # - weights, [B, T]\n","\n","            outputs, decoder_hidden, attention_weights = self.decoder.forward(\n","                    input=decoder_input.long(),\n","                    prev_hidden=decoder_hidden,\n","                    encoder_outputs=encoder_outputs,\n","                    seq_len=input_lengths)\n","            \n","            alignments[t] = attention_weights.transpose(1, 0)\n","            \n","            \n","            logits[t] = outputs\n","\n","            \n","\n","            if  self.training:\n","                decoder_input = targets[:, t]\n","            else:\n","                topv, topi = outputs.data.topk(1) # 가장 높은 예측만 사용.\n","                decoder_input = topi.squeeze(-1).detach()\n","                inference.append(decoder_input.cpu())\n","\n","        \n","        labels = targets.contiguous().view(-1) \n","\n","        \n","        mask_value = 0\n","        #what is this mask_3d? # (warning check)\n","        logits = mask_3d(logits.transpose(1, 0), targets_lengths, mask_value)\n","        logits = logits.contiguous().view(-1, self.vocab_size) # loss를 구하기 위해 쫙 펴주기 \n","\n","        return logits, labels.long(), alignments,inference\n","\n","    \n","    def step(self, batch):\n","        x, y, x_len, y_len = batch\n","        if self.gpu:\n","            x = x.cuda()\n","            y = y.cuda()\n","            x_len = x_len.cuda()\n","            y_len = y_len.cuda()\n","\n","        encoder_out, encoder_state = self.encode(x, x_len) # encoder \n","        logits, labels, alignments,inference = self.decode(encoder_out, encoder_state, y, y_len, x_len) # decoder 를 통해 alignment와 logit 값 얻기 \n","        return logits, labels, alignments,inference\n","\n","    def loss(self, batch):\n","        logits, labels, alignments,inference = self.step(batch)\n","        loss = self.loss_fn(logits, labels) # loss 구하기 우리는 cross entropy 사용 \n","        return loss, logits, labels, alignments,inference"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xbOfjOmU6262","colab_type":"text"},"source":["### Train the model"]},{"cell_type":"markdown","metadata":{"id":"weB4hLTwfV3S","colab_type":"text"},"source":["![대체 텍스트](https://pytorch.org/tutorials/_images/seq2seq.png)"]},{"cell_type":"code","metadata":{"id":"NKYVKohKBmpS","colab_type":"code","colab":{}},"source":["def train(model, optimizer, train_loader, epoch,n_epochs):\n","    \n","\n","    losses = []\n","    cers = []\n","\n","    \n","    model.train() # train mode \n","    count = 0\n","    for batch in train_loader:\n","        loss, _, _, _,_ = model.loss(batch)\n","        losses.append(loss.item())\n","        # Reset gradients\n","        optimizer.zero_grad()\n","        # Compute gradients\n","        loss.backward()\n","        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2)\n","        ## torch.nn.utils.clpi_grad_nrom_(model.parameters(), max_norm=2)\n","        optimizer.step()\n","  \n","    print ('\\n [{}/{}] avg_loss= {:05.3f}'.format(epoch,n_epochs,np.mean(losses)))\n","    \n","    return model, optimizer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"I0q5dl-qGtXB","colab_type":"code","colab":{}},"source":["def evaluate(model, eval_loader):\n","\n","    losses = []\n","    accs = []\n","    edits = []\n","    \n","    model.eval() # why??  dropout이 꺼진다~~\n","\n","    with torch.no_grad(): ##어떤 메모리를 사용하지 말라~~ backprop 하기 위해서!\n","        for batch in eval_loader:\n","            #t.set_description(\" Evaluating... (train={})\".format(model.training))\n","            loss, logits, labels, alignments,_ = model.loss(batch)\n","            preds = logits.detach().cpu().numpy()\n","            \n","            acc = 100 *np.sum(np.argmax(preds, -1) == labels.detach().cpu().numpy()) / len(preds)\n","            edit = editdistance.eval(np.argmax(preds, -1), labels.detach().cpu().numpy()) / len(preds)\n","            \n","            losses.append(loss.item())\n","            \n","            accs.append(acc)\n","            edits.append(edit)\n","        \n","        \n","\n","   \n","    print(\"  End of evaluation : loss {:05.3f} , acc {:03.1f} , edits {:03.3f}\".format(np.mean(losses), np.mean(accs), np.mean(edits)))\n","    \n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GWWvvbf68__6","colab_type":"text"},"source":["## 학습을 진행해보도록 하겠습니다"]},{"cell_type":"code","metadata":{"id":"N6zoFKQj8_MU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"64276931-59e7-4bbc-8e51-e534b84944c7","executionInfo":{"status":"ok","timestamp":1564647613231,"user_tz":-540,"elapsed":878,"user":{"displayName":"IkJong P","photoUrl":"https://lh5.googleusercontent.com/-XMHI3In5VGY/AAAAAAAAAAI/AAAAAAAATWk/u_tsKGQQW3I/s64/photo.jpg","userId":"13049101358773066030"}}},"source":["USE_CUDA = torch.cuda.is_available()\n","batch_size = 32\n","epochs = 6\n","dataset = ToyDataset(5, 15)\n","eval_dataset = ToyDataset(5, 15, type='eval')"],"execution_count":18,"outputs":[{"output_type":"stream","text":["{'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7}\n","{'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PKechkHv9EXQ","colab_type":"code","colab":{}},"source":["train_loader = data.DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=pad_collate, drop_last=True)\n","eval_loader = data.DataLoader(eval_dataset, batch_size=batch_size, shuffle=False, collate_fn=pad_collate,drop_last=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JapBBgq6KNp2","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"xh2HQkg59sND","colab_type":"code","colab":{}},"source":["config = {\n","  \"decoder\": \"Bahdanau\",\n","  \"encoder\": \"RNN\",\n","  \"n_channels\": 4,\n","  \"encoder_hidden\": 64,\n","  \"encoder_layers\": 1,\n","  \"encoder_dropout\": 0.2,\n","  \"bidirectional_encoder\": False,\n","  \"decoder_hidden\": 64,\n","  \"decoder_layers\": 1,\n","  \"decoder_dropout\": 0.2,\n","  \"n_classes\":dataset.VOCAB_SIZE+3 ,\n","  \"batch_size\": 32,\n","  \"embedding_dim\": 64,\n","  \"attention_score\": \"concat\",\n","  \"learning_rate\": 0.001,\n","  \"gpu\": True,\n","  \"loss\": \"cross_entropy\"\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"N_h_LOmU-AEz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":72},"outputId":"f2126855-a9a5-496b-94fc-e890d6e9df93","executionInfo":{"status":"ok","timestamp":1564647955109,"user_tz":-540,"elapsed":1082,"user":{"displayName":"IkJong P","photoUrl":"https://lh5.googleusercontent.com/-XMHI3In5VGY/AAAAAAAAAAI/AAAAAAAATWk/u_tsKGQQW3I/s64/photo.jpg","userId":"13049101358773066030"}}},"source":["model = Seq2Seq(config)\n","model = model.cuda()"],"execution_count":31,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:54: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"_jXTGn9V-CuD","colab_type":"code","colab":{}},"source":["optimizer = torch.optim.Adam(model.parameters(), lr=config.get(\"learning_rate\", .001))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ktMBioF-EAN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":369},"outputId":"07c9ba42-b00f-48a9-87a2-f0904ae20a22","executionInfo":{"status":"ok","timestamp":1564648097677,"user_tz":-540,"elapsed":142783,"user":{"displayName":"IkJong P","photoUrl":"https://lh5.googleusercontent.com/-XMHI3In5VGY/AAAAAAAAAAI/AAAAAAAATWk/u_tsKGQQW3I/s64/photo.jpg","userId":"13049101358773066030"}}},"source":["for epoch in range(epochs):\n","  model,optimizer  = train(model,optimizer, train_loader,epoch,epochs)\n","  evaluate(model,eval_loader)\n"," "],"execution_count":33,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1374: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"],"name":"stderr"},{"output_type":"stream","text":["\n"," [0/6] avg_loss= 1.384\n","  End of evaluation : loss 1.329 , acc 55.5 , edits 0.341\n","\n"," [1/6] avg_loss= 0.958\n","  End of evaluation : loss 1.186 , acc 64.3 , edits 0.291\n","\n"," [2/6] avg_loss= 0.726\n","  End of evaluation : loss 1.067 , acc 69.6 , edits 0.242\n","\n"," [3/6] avg_loss= 0.612\n","  End of evaluation : loss 0.976 , acc 72.9 , edits 0.220\n","\n"," [4/6] avg_loss= 0.532\n","  End of evaluation : loss 0.926 , acc 75.6 , edits 0.194\n","\n"," [5/6] avg_loss= 0.455\n","  End of evaluation : loss 0.895 , acc 77.5 , edits 0.181\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5RNRT6acajT5","colab_type":"text"},"source":["### 시각화"]},{"cell_type":"code","metadata":{"id":"cQ77ZlPKal2j","colab_type":"code","colab":{}},"source":["import seaborn\n","\n","def draw(data, x, y):\n","    seaborn.heatmap(data, \n","                    xticklabels=x, square=True, yticklabels=y, vmin=0.0, vmax=1.0, \n","                    cbar=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"h3fVzxjganHg","colab_type":"code","colab":{}},"source":["def visualize_plot(model,custom_input= 'cgdafa'):\n","    c_xs = np.array([dataset.char2int.get(x) for x in custom_input]+[2])\n","    c_xs = torch.from_numpy(c_xs).unsqueeze(0).long()\n","\n","    c_xl = torch.tensor(c_xs[0].size()[-1]).unsqueeze(0)\n","\n","    c_ys = np.array([dataset.char2int.get(x) for x in custom_input[::-1]] + [2]) # Return the random string and its reverse + EOS \n","    c_ys = torch.from_numpy(c_ys).unsqueeze(0).long()\n","\n","    c_yl = torch.tensor(c_ys[0].size()[-1]).unsqueeze(0)\n","    c_data = (c_xs,c_ys,c_xl,c_yl)\n","    loss, logits, labels, alignments,predict=model.loss(c_data)\n","    heat_map_value = alignments.detach().cpu().numpy()[:, :, 0]\n","    preds = logits.detach().cpu().numpy()\n","    preds = np.argmax(preds, -1)\n","    source_tokens = [ dataset.int2char[item-3] for item in c_xs[0] if item!=0 if item !=2 ] +['</s>']\n","    target_tokens = [ dataset.int2char[item-3] if item !=2 else '</s>' for item in preds.tolist() if item!=0 ]\n","    draw(heat_map_value,source_tokens,target_tokens)\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4IkbDmwaY4BG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":304},"outputId":"df950b21-a526-45f5-e47c-6afd236198d1","executionInfo":{"status":"ok","timestamp":1564648111450,"user_tz":-540,"elapsed":1248,"user":{"displayName":"IkJong P","photoUrl":"https://lh5.googleusercontent.com/-XMHI3In5VGY/AAAAAAAAAAI/AAAAAAAATWk/u_tsKGQQW3I/s64/photo.jpg","userId":"13049101358773066030"}}},"source":["visualize_plot(model,'cbada')"],"execution_count":36,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1374: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPwAAAD8CAYAAABTq8lnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"ZZdAsEpjcC0V","colab_type":"text"},"source":["### Dot Mode "]},{"cell_type":"code","metadata":{"id":"T8X3wWrrewkY","colab_type":"code","colab":{}},"source":["config = {\n","  \"decoder\": \"Bahdanau\",\n","  \"encoder\": \"RNN\",\n","  \"n_channels\": 4,\n","  \"encoder_hidden\": 64,\n","  \"encoder_layers\": 1,\n","  \"encoder_dropout\": 0.2,\n","  \"bidirectional_encoder\": False,\n","  \"decoder_hidden\": 64,\n","  \"decoder_layers\": 1,\n","  \"decoder_dropout\": 0.2,\n","  \"n_classes\":dataset.VOCAB_SIZE+3 ,\n","  \"batch_size\": 32,\n","  \"embedding_dim\": 64,\n","  \"attention_score\": \"concat\",\n","  \"learning_rate\": 0.001,\n","  \"gpu\": True,\n","  \"loss\": \"cross_entropy\"\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8xHTy6m9k7XU","colab_type":"code","colab":{}},"source":["model = Seq2Seq(config)\n","model = model.cuda()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LuAGn6wOcMAU","colab_type":"code","colab":{}},"source":["optimizer = torch.optim.Adam(model.parameters(), lr=config.get(\"learning_rate\", .001))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6NNv1KexcOQh","colab_type":"code","colab":{}},"source":["for epoch in range(epochs):\n","  model,optimizer  = train(model,optimizer, train_loader,epoch,epochs)\n","  evaluate(model,eval_loader)\n"," "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"48ACZ__zcgz3","colab_type":"code","colab":{}},"source":["visualize_plot(model,'cbada')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jZio7ZpScXWf","colab_type":"text"},"source":["### Concat Mode "]},{"cell_type":"code","metadata":{"id":"rlEMn4CDcVdv","colab_type":"code","colab":{}},"source":["config = {\n","  \"decoder\": \"Bahdanau\",\n","  \"encoder\": \"RNN\",\n","  \"n_channels\": 4,\n","  \"encoder_hidden\": 64,\n","  \"encoder_layers\": 1,\n","  \"encoder_dropout\": 0.2,\n","  \"bidirectional_encoder\": False,\n","  \"decoder_hidden\": 64,\n","  \"decoder_layers\": 1,\n","  \"decoder_dropout\": 0.2,\n","  \"n_classes\":dataset.VOCAB_SIZE+3 ,\n","  \"batch_size\": 32,\n","  \"embedding_dim\": 64,\n","  \"attention_score\": \"concat\",\n","  \"learning_rate\": 0.001,\n","  \"gpu\": True,\n","  \"loss\": \"cross_entropy\"\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KvMOke61cbvf","colab_type":"code","colab":{}},"source":["model = Seq2Seq(config)\n","model = model.cuda()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xCRpTxKVcc__","colab_type":"code","colab":{}},"source":["optimizer = torch.optim.Adam(model.parameters(), lr=config.get(\"learning_rate\", .001))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mjbdwe3jcfFD","colab_type":"code","colab":{}},"source":["for epoch in range(epochs):\n","  model,optimizer  = train(model,optimizer, train_loader,epoch,epochs)\n","  evaluate(model,eval_loader)\n"," "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uhnkBB82chid","colab_type":"code","colab":{}},"source":["visualize_plot(model,'cbada')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uMzGeSiUdZRo","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}